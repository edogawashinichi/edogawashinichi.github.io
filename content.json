{"pages":[],"posts":[{"title":"Brew Install 报错","text":"Problem123$ brew updatefatal: gitError: another SolutionqitaCSDNstackoverflow","link":"/2021/03/26/Brew-Install-%E6%8A%A5%E9%94%99/"},{"title":"DeepFM 实战","text":"Github 下载轮子注意事项 从 Tensorflow2.0 切换到 1.14.0 Python 切换到 3.6.8 手动下载添加 yellowfin 包 下载 Kaggle 数据","link":"/2021/08/30/DeepFM-%E5%AE%9E%E6%88%98/"},{"title":"FM 模型训练问题汇总","text":"problem 0DataFrame 转置再转字典 12dv = DictVectorizer()X_train_vec = dv.fit_transform(list(X_train.T.to_dict().values)) 出现告警 1Warning: DataFrame columns are not unique, some columns will be omitted python solution转置之前的行索引index有duplicate 12345678910111213141516X_train = df_train[fm_feature_cols]y_train = df_train[LABEL_COL].valuesy_train_cls = (y_train&gt;=PARAM_LABEL_THRES).astype(np.int32)X_test = df_test[fm_feature_cols]y_test = df_test[LABEL_COL].valuesy_test_cls = (y_test&gt;=PARAM_LABEL_THRES).astype(np.int32)print('is X_train.index unique? {0}'.format(X_train.index.is_unique))print('is X_test.index unique? {0}'.format(X_test.index.is_unique))X_train.reset_index(drop=True, inplace=True)X_test.reset_index(drop=True, inplace=True)dv = DictVectorizer()X_train_vec = dv.fit_transform(list(X_train.T.to_dict().values))X_test_vec = dv.transform(list(X_test.T.to_dict().values))fm = pylibfm.FM(num_factors=10, num_iter=iters, verbose=True, task='classification', init_learning_rate=0.001, learning_rate_schedule='optimal')fm.fit(X_train, y_train_cls)preds = fm.predict(X_test_vec) problem 112345678910X_train = df_train[fm_feature_cols]y_train = df_train[LABEL_COL].valuesy_train_cls = (y_train&gt;=PARAM_LABEL_THRES).astype(np.int32)X_test = df_test[fm_feature_cols]y_test = df_test[LABEL_COL].valuesy_test_cls = (y_test&gt;=PARAM_LABEL_THRES).astype(np.int32)dv = DictVectorizer()X_train_vec = dv.fit_transform(list(X_train.T.to_dict().values))X_test_vec = dv.transform(list(X_test_vec.T.to_dict().values))fm.fit(X_train_arr, y_train_cls) 报错 1ValueError: Found input variables with inconsistent numbers of samples 原因 12345print('len(X_train_arr)={0}'.format(X_train_arr.shape[0]))print('len(y_train_cls)={0}'.format(len(y_train_cls)))#len(X_train_arr)=245299#len(y_train_cls)=503458#X_train 和 y_train_cls 长度不一致 solution123dv = DictVectorizer()X_train_vec = dv.fit_transform(list(X_train.T.to_dict().values()))X_test_vec = dv.transform(list(X_test.T.to_dict().values())) problem 21TypeError: sparse matrix length is ambiguous; use getnnz() or shape[0] solution12print('len(X_train)={0}'.format(len(X_train)))print('len(y_train_cls={0}'.format(len(y_train_cls))) 这里没问题 1234567dv = DictVectorizer()X_train_vec = dv.fit_transform(list(X_train.T.to_dict().values()))X_test_vec = dv.transform(list(X_test.T.to_dict().values()))print('len(X_train_vec)={0}'.format(len(X_train_vec)))print('len(y_train_cls)={0}'.format(len(y_train_cls)))print('len(X_test_vec)={0}'.format(len(X_test_vec)))print('len(y_test_cls)={0}'.format(len(y_test_cls))) 这里报错，改为 1234567dv = DictVectorizer()X_train_vec = dv.fit_transform(list(X_train.T.to_dict().values()))X_test_vec = dv.transform(list(X_test.T.to_dict().values()))print('len(X_train_vec)={0}'.format(X_train_vec.shape[0]))print('len(y_train_cls)={0}'.format(len(y_train_cls)))print('len(X_test_vec)={0}'.format(X_test_vec.shape[0]))print('len(y_test_cls)={0}'.format(len(y_test_cls))) problem 3使用 DictVectorizer 向量化 DataFrame由于 DataFrame 数据量超过 1G自动转为 scipy.sparse.sparse.csr.csr_matrix 类型不能直接用于 pylibfm.FM.fit先将 csr_matrix 转为 list 再训练内存超过此 Python 进程内存达到 270 G 直接爆掉触发 OOM 从而 linux 内核 kill 该进程 problem 4训练 pylibfm.FM 模型 12-- Epoch 161Training log loss: nan solution可能列的数据类型问题 =&gt; 检查发现问题(object类型需要转成string类型，但不影响训练结果)目前 github 项目 pyFMclassification存在bug两次调用sigmoid函数01 classification log loss 改为 regression mse problem 501分类应用regression模型 12fm = pylibfm.FM(num_factors=10, num_iters=iters, verbose=True, task='regression', init_learning_rate=0.001, learning_rate_schedule='optimal')fm.fit(X_train_arr, y_train_cls) 报错 1ValueError: Buffer dtype mismatch, expected 'DOUBLE' but got 'int' solution1y_train_cls = (y_train.values&gt;=PARAM_LABEL_THRES).astype(np.float64) problem 6分类改为回归 12fm = pylibfm.FM(num_factors=10, num_iters=iters, verbose=True, task='regression', init_learning_rate=0.001, learning_rate_schedule='optimal')fm.fit(X_train_arr, y_train_cls) 仍然出现问题 12-- Epoch 1Training MSE: nan solution少数据量/多数据量分别测一下=&gt; 少量数据 classification 正常 problem 7少数据量测试报错 123-- Epoch 1Training MSE: nanValueError: Input contains NaN, infinity or a value too large for dtype('float64') 回归 label 训练溢出（可能原因是某些特征未归一化） solution=&gt;直接改为分类-&gt;NaN=&gt;改为分类并且特征归一化-&gt;结果正常(1000样本) 结果正常(10000样本) 临界点60万样本120特征 内存不足(全部样本) problem 8模型验证 12preds = fm.predict(X_test_csr)test_logloss = log_loss(y_test_cls, preds) 报错 12ValueError: y_true contains only one label (0).Please provide the true labels explicitly through the labels argument. solution验证集的label全为0没有1随机划分训练集验证集=&gt;分层划分 12345678910111213141516def split_train_valid_random(df, test_frac=0.1): df = df.sample(frac=1).reset_index(drop=True, inplace=True) n_test = int(len(df) * test_frac) df_test, df_train = df[:n_test], df[n_test:] df_train.reset_index(drop=True, inplace=True) df_test.reset_index(drop=True, inplace=True) return df_train, df_testdef split_train_valid_stratify(df, primary_key='chatroom_id', label='clickuv', test_frac=0.1): df = df.drop_dumplicates(subset=[primary_key, label]) x = df[primary_key].values y = df[label].values y = (y / 3).astype(int) y[np.where(y &gt; 5)] = 5 row_train, row_test, _, _, = train_test_split(x, y, stratify=y, test_size=test_frac) return row_train, row_test","link":"/2021/08/13/FM-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/"},{"title":"FM 系列模型性能比较","text":"基本 FM 模型包 libfm | C++11 pywfm | python alphaFM | C++11 fastFm | C/Cython/Python pyFM | Python libFM | Tensorflow spark-libFM | scala DiFacto | C++ pyFM 测试 实验序号 raw features linear features factors iters 训练时间 总时间 训练集 row 训练集 logloss 验证集 row 验证集 logloss 验证集 auc 验证集 acc 测试集 row 测试集 logloss 测试集 auc 测试集 acc 机器 1 124 40w 10 20 1h38m 2h36m 518648 0.33822 162770 0.3947 0.8268 0.8303 31979 1.1479 0.6123 0.2320 luban 服务器 2 124 40w 15 30 4h4m 4h52m 518742 0.30285 162548 0.3635 0.8564 0.8503 31979 1.1922 0.5778 0.2511 luban 服务器 3 4 2w 15 30 1h49m 2h41m 4000000 0.31214 1000000 0.3669 0.8342 0.8480 31979 1.8640 0.4074 0.1390 luban 服务器 4 4 2w 4 60 2h57m 3h15m 5000000 0.30302 1250000 0.3673 0.8333 0.8477 31979 1.9496 0.5598 0.1653 luban 服务器 5 4 2w 8 60 3h16m 4h15m 5000000 0.28222 1250000 0.3492 0.8489 0.8575 31979 1.9372 0.5023 0.1454 luban 服务器 6 4 2w 30 30 4h19m 5h18m 5000000 0.28640 1250000 0.3478 0.8461 0.8585 31979 1.8359 0.4332 0.1513 luban 服务器 7 22 8w 30 30 6h18m 7h9m 2000000 0.29670 500000 0.3769 0.8208 0.8457 31979 2.3700 0.6774 0.0919 luban 服务器 8 22 8w 20 30 4h20m 5h10m 2000000 0.30264 500000 0.3809 0.8165 0.8437 31979 2.2959 0.4705 0.1144 luban 服务器 9 22 8w 20 30 4h31m 5h28m 2000000 0.28568 500000 0.3750 0.8208 0.8474 31979 2.1205 0.2859 0.1672 luban 云平台 10 22 8w 40 40 22h28m 23h33m 4000000 0.20939 1000000 0.2838 0.9051 0.8923 31979 4.3235 0.7143 0.1193 luban 云平台 11 22 8w 40 40 43h58m 46h43m 7846452 0.26457 2000000 0.3044 0.8927 0.8766 1453918 0.4240 0.7056 0.8524 luban 云平台 train_all (features=124) 效果不佳train_naked (features=4) 近似随机噪声train_basic (features=22) ‘硬train一发‘测试集AUC提升至0.7","link":"/2021/08/23/FM-%E7%B3%BB%E5%88%97%E6%A8%A1%E5%9E%8B%E6%80%A7%E8%83%BD%E6%AF%94%E8%BE%83/"},{"title":"Kruskal 习题集合","text":"Easy 入门暂无 Medium 普及 LeetCode 1631 Path With Minimum Effort 最小体力消耗路径题解 哔哩哔哩 西瓜视频推荐度 ☆☆☆ LeetCode 1584 Min Cost to Connect All Points 连接所有点的最小代价题解 哔哩哔哩 西瓜视频推荐度 ☆☆☆☆ Hard 提高暂无","link":"/2021/02/01/Kruskal-%E4%B9%A0%E9%A2%98%E9%9B%86%E5%90%88/"},{"title":"Manim 中文教程","text":"中文速成包含 背景图片","link":"/2021/08/16/Manim-%E4%B8%AD%E6%96%87%E6%95%99%E7%A8%8B/"},{"title":"ParseException line x:y cannnot recognize input near","text":"problemlinux 命令行执行 hive sql 脚本 run.sh 1234567#!/bin/shsource /etc/profilesource ~/.bash_profileyest=$(date -d &quot;-1 days&quot; &quot;+%Y-%m-%d&quot;)yest2=$(date -d &quot;-2 days&quot; &quot;+%Y-%m-%d&quot;)hive -hiveconf YEST_DATE${yest} YEST2_DATE=${yest2} -f test.sql &gt; test.csv 报错 1FAILED: ParseException line xx:yy cannot recognize input near '$' '{' 'hivevar' in select clause 1FAILED: ParseException line xx:yy cannot recognize input near 'where' 'city_id' '=' in subquery source solution脚本 test.sql 存在语法不严谨","link":"/2021/08/23/ParseException-line-x-y-cannnot-recognize-input-near/"},{"title":"Permutation Importance","text":"Scikit-learn の Random Forest の Permutation importance を計算Sckit-learn的Random Forest的featureimportance_ 是Gini importance，可能有偏差。如果在意偏差的话，可以使用rfpimp等模块来计算并评价Permutation importance。 背景Random Forest对不需要计算成本却能显示出良好的预测性能非常满意，不过也有非线性的，说明变量的重量没有正负，评价也有困难的时候。 我觉得没有什么好的方法，查了很多之后，因为是千回百转的学习，所以作为备忘录整理好。 结果找到了以下的Repository。parrt/random-forest-importances 嗯，好像计算Permutation importance的重量的module。想着Permutation importance是什么呢，正好用日语整理的Tweet被Retweet了。Twitter好厉害。 用构建了OOB和外部套装等预测模型构筑中未使用的数据的预测模型进行预测，以当时的预测性能为基础线。然后，将某个说明变量的值像y-randomization那样打乱，构建预测模型，同样计算预测性能。那个时候，那个说明变量越重要预测性能就越大。通过各说明变量将其作为重要度的是Permutation Importance。 嗯，Random Forest的重要性例如像以下幻灯片的第8张那样“在制作决定木后随机地更换说明变量。之后预测OOB，根据更换前和预测性能的差来计算”，所以“感觉差不多，差别也会有那么大的变化吗？”一开始是这么想的。 但是，从最初介绍的rfpimp首页的链接可以进行的这个Repository作者的博客里有以下文章。https://explained.ai/rf-importance/index.html 123The most common mechanism to compute feature importances, and the one used in scikit-learn’s RandomForestClassifier and RandomForestRegressor, is the mean decrease in impurity (or gini importance) mechanism (check out the Stack Overflow conversation). 在Scikit-learn中，各说明变量的重要性是用Gini importance这个指标来计算的。 Gini importance简单来说就是Gini系数越小越容易判别的值，由于各说明变量的关系，需要变小多少的指标。如果是日语的话，以下的网站比较容易理解。 因为是难得的机会，所以在Sckit-learn的module中也试着看了一下。RandomForestClassifier在其中使用DecisionTreeClassifier。而且DecisionTreeClassifier好像使用了其中cython写的代码。所以才高速的吧。我虽然不能读cython，但是我发现了可能是这里的部分。 可以看出是取了差别作为importance。另外，DecisionTreeClassifier的Docomentation上也写着使用Gini importance。 也就是说，Sckit-learn的Random Forest的说明变量的重量是“在制作决定树后随机更换说明变量。之后预测OOB，根据更换前和预测性能的差来计算”，这是我的误解，实际上是使用Gini importance的。 因此，Repository的作者制作了寻求Permutation importance的module。终于理解了。学到了很多。 关于rfpimp module学习了很多东西，这次请允许我省略。不仅可以简单地计算Permutation importance，还可以汇总多个说明变量来计算Permutation importance，我觉得这是非常有趣的module。刚才介绍的作者的博客上也写了偏颇情况的说明，Jupter Notebook上也有易懂的Example，真是帮了我大忙了。 最后Gini importance当然也有好的地方，那就是重量计算快的地方之一。因为Permutation importance在其性质上需要多次进行预测模型构筑，所以比起Gini importance，计算权重更花费时间，可以说很容易地反复进行。 另一方面，Permutation importance不仅适用于Random Forest，也适用于其他机器学习方法，特别是对SVM等以往说明变量的权重无法得到的方法，由此可求出说明变量的权重。请一定要熟练使用。","link":"/2021/09/02/Permutation-Importance/"},{"title":"Revival","text":"回归 Github 博客2021 伊始，疫情已延烧一年之久，开源节流刻不容缓，遂由阿里云服务器 + 域名 + WordPress 回归 Github 免费个人主页。 Git+Hexo 搭建博客搭建教程可 Google 之，这里仅对注意事项作一个 remark。 blog 配置文件 __config.yml 添加自定义主题 theme: icarus 前面不要有空格，否则无法识别 注意执行各种命令的路径不能弄乱套，实在不行就删除 blog 文件夹重新 npm 下载 hexo-cli github 的 repository 添加 README.md 在 hexo d 之后被删除，Hexo 如何配置 icarus 主题自定义头像路径 css/images/avatar.png，icarus 网站图标路径 img/logo.png，可在 github 的 repository 中看到 分享链接需要注册 addthis 自定义样式，获取 install_url，修改 sharethis 为 addthis，url 必须加单引号 donate 的 qrcode 可用支付宝和微信收款码，与 logo 放在一起，路径不需加单引号 disqus 邮箱注册之后必须 get started 才能看到 Website Name (shortname)，直接登录账号进行 setting 是不行的，接下来 select platform 时选择最后的手动安装直接 configure","link":"/2021/01/28/Revival/"},{"title":"SPARK SQL ...including 1 partition column(s) having constant value(s)","text":"Solution 1select * from partitioned_table导致不能被选择的常数分区列将脚本中所有的 select * 展开为每一列REF 2彻底删除整个表drop table if exists table_dev; √alter table table_dev if exists partition (dt=’year-month-day’); × 3通过改变create table if not exists table_dev (col1 string, col2 string) partitioned by (dt string);中的列的数量发现问题2 4调试的方法一个是单元测试，一个是AB测试","link":"/2021/07/30/SPARK-SQL-including-1-partition-column-s-having-constant-value-s/"},{"title":"Swing&#x2F;user-cf&#x2F;item-cf召回算法","text":"introductionSwing 意为荡秋千，表示 item-user-item 三角关系，该算法是阿里提出的召回算法，对物品 i,j 的所有共同购买用户 U，计算从任意两个用户 u,v 的角度得到 i,j 的相似度$s(u,v,i,j)=\\frac{1}{\\alpha + \\left|I_u\\cap I_v\\right|}$然后求和得到 i,j 的相似度$\\textbf{sim}(i,j) = \\sum_{u\\in U}\\sum_{v\\in U} s(u,v,i,j)$ user-cf 基于相似用户之间的物品扩散item-cf 基于相似物品之间的用户扩散二者做复合运算，与分开两路召回相比，复杂度多一层循环，对用户推荐的物品增多可考虑基于四部图随机游走的 tradeoff 方案 question该算法的假设是若两用户 u,v 除 i,j 外的共同购买物品越多，则 i,j 相似度越低若两用户 u,v 除 i,j 外的共同购买物品越少，则 i,j 相似度越高这个假设难以理解，我的观点如下：若两用户 u,v 除 i,j 外的共同购买物品越多，则 u,v 相似度越高若两用户 u,v 除 i,j 外的共同购买物品越少，则 u,v 相似度越低这表示 i,j 具有强转移性，所以 Swing 算法召回的是具有强转移性(互补/关联)的物品，而不是具有相似性的物品","link":"/2021/08/09/Swing-%E5%8F%AC%E5%9B%9E%E7%AE%97%E6%B3%95/"},{"title":"Tao","text":"0选择一两个可谋生或有兴趣的赛道 纵向有节奏提升 横向对齐高端玩法 1系统思维框架 总体完整 细节可执行可展示 2结果导向 模块化拆解组装 路径可回溯复盘","link":"/2021/08/21/Tao/"},{"title":"Union Find Set 习题集合","text":"Easy 入门暂无 Medium 普及 洛谷 P3367 【模板】并查集题解 哔哩哔哩 西瓜视频推荐度 ☆☆☆☆☆ Hard 提高暂无","link":"/2021/02/02/Union-Find-Set-%E4%B9%A0%E9%A2%98%E9%9B%86%E5%90%88/"},{"title":"fastFM 安装","text":"Github 多次下载 zipfastFM-core 包含两个外部项目","link":"/2021/08/31/fastFM-%E5%AE%89%E8%A3%85/"},{"title":"fatal unable to access github","text":"problem 1部署 hexo 1hexo d 报错 1fatal: unable to access 'https://github.com/edogawashinichi/edogawashinichi.github.io.git/': The requested URL returned error: 403 solution2021-08-13 起 github 不再允许自动保存密码Personal Access Token kartik tyagi problem 2部署 hexo 1hexo d 报错 1fatal: unable to access 'https://github.com/edogawashinichi/edogawashinichi.github.io.git/': Failed to connect to github.com port 443: Operation timed out 或 1fatal: unable to access 'https://github.com/edogawashinichi/edogawashinichi.github.io.git/': LibreSSL SSL_connect: SSL_ERROR_SYSCALL in connection to github.com:443 solution网络问题，重复执行几次 hexo d","link":"/2021/08/16/fatal-unable-to-access-https-github-com-edogawashinichi-edogawashinichi-github-io-git/"},{"title":"hexo back","text":"知乎太坑，转回github。 环境调通好久不用，环境有些问题，解决https://blog.csdn.net/eagleuniversityeye/article/details/85267550在package.json目录下执行npm install hexo-server –save 命令忘差不多了，攒起来同样在package.json目录下启动本地服务 hexo s写文章 hexo new “文章标题”清空public下的内容 hexo clean把source的内容生成到public下 hexo g把public下的内容同步到github仓库 hexo d github需要使用PAT代替密码进行远程连接解决https://stackoverflow.com/questions/68775869/message-support-for-password-authentication-was-removed 用的免费梯子，hexo d经常连不上githubfatal: unable to access ‘https://github.com/需要多试几次（一般需要3次）hexo d成功github.io页面刷新一般也存在一定延时 hexo d同步自动使用github原来的账号密码解决：把https方式改为http方式https://www.lintstar.top/2021/08/4b8ee7df.html#Hexo-连接-Github host key verification failed原因是github.com更换了ip解决：重新连接保存到本地https://timmousk.com/blog/host-key-verification-failed-git/ git@github.com: Permission denied (publickey)原因：github新版本删除了原来的mac笔记本的ssh-pubkey解决：github增加两个ssh-pubkey（authentication,signing)https://docs.github.com/en/authentication/connecting-to-github-with-ssh/adding-a-new-ssh-key-to-your-github-account github加载不出settings页面解决：直接输入https://github.com/settings回车 发博客流程命令行都在package.yml所在路径下执行 本地创建文章1hexo new &quot;文章标题&quot; 编辑文章使用sublime或vim 重新渲染生成网页12hexo cleanhexo g 本地预览1hexo s 浏览器登录localhost:4000 同步到远程1hexo d","link":"/2024/02/29/hexo-back/"},{"title":"install pyFM","text":"手动安装国内 github 不稳定，先下载再安装 在https://github.com/coreylynch/pyFM中手动下载包 将包解压，更改里面的setup.py文件，去掉setup.py文件里面的libraries=[“m”]一行 cd到当前文件夹下python setup.py install 参考","link":"/2021/08/12/install-pyFM/"},{"title":"macOS Linux 文件解压缩","text":"Linux 文件解压12sudo yum install p7zip7za x file.7z macOS 文件压缩17z a dest.7z src_folder macOS 文件解压127z x file.7z7z x file.rar","link":"/2021/08/30/macOS-Linux-%E6%96%87%E4%BB%B6%E8%A7%A3%E5%8E%8B%E7%BC%A9/"},{"title":"model saving disabled","text":"problem在 jupyter notebook 上打开保存的模型文件报错 123Error! ./models/fm_scaler.mdl is not UTF-8 encodedSaving disabled.See Console for more details. solution误导性输出因为 jupyter 无法打开二进制文件服务器终端查看文件类型 12file fm_scaler.mdlfm_scaler.mdl 8086 relocatable (Microsoft)","link":"/2021/08/20/model-saving-disabled/"},{"title":"no module named tkinter","text":"problem执行 Python 脚本 1import matplotlib.pyplot as plt 报错 1ModuleNotFoundError: No module named '_tkinter' solution需要重新安装Python","link":"/2021/08/16/no-module-named-tkinter/"},{"title":"pyFM vs fastFM","text":"Translation 使用 Movielens 尝试分解机 Python 实现 pyFM、fastFM——2019 年 12 月 11 日你好，我是 Guglilac (@guglilac)。 本文是关于对 Movielens 数据集使用 pyFM 和 fastFM 这两个最大的因子分解机 (FM) 的 Python 实现。 如何使用fastFMGitHub - ibayer/fastFM: fastFM: A Library for Factorization Machines 据说不仅可以使用回归和分类，还可以使用 BPR 损失来预测排名，但是在另一个人的文章中，BPR 不起作用。 我也和这篇文章分开试过BPR loss，但是没学好。在本文中，Movielens 用于评分预测，所以让我们仅使用回归模型来学习。 输入以与 pyFM 相同的方式作为 scipy 的稀疏矩阵给出。结果只贴pyFM，这里只贴写法。 只需初始化并正常安装即可。 123from fastFM import als,sgdmodel = als.FMRegression(n_iter=100, l2_reg_w=0.1, l2_reg_V=0.1, rank=10)model.fit(X_train,y_train) 但是，默认情况下，根本不显示学习历史，也不应用学习曲线，因此不清楚学习是否在进行。 如果你查一下，指南 — fastFM 0.2.10 文档 正如本页所写，似乎您需要自己实现显示学习历史的部分。 当我试图模仿它时， 12345678910111213141516171819202122from sklearn.metrics import mean_squared_errorimport numpy as npdef get_rmse(model,X, y): y_pred=model.predict(X) return np.sqrt(mean_squared_error(y_pred, y))def train(model,X_train,y_train,n_iter,iter_size=1): model.fit(X_train,y_train) # initのためにこれが必要 rmse_hist=[] iter_size=1 for i in range(n_iter): model.fit(X_train, y_train,n_more_iter=iter_size) rmse_train=get_rmse(model,X_train,y_train) rmse_hist.append(rmse_train) if (i+1)%10==0: print(f&quot; epoch = {i+1}, Train RMSE : {rmse_train: 0.4f}&quot;) return model,rmse_histmodel = als.FMRegression(n_iter=0, l2_reg_w=0.1, l2_reg_V=0.1, rank=10)model,history=train(model,X_train,y_train, n_iter=100) 需要实现模型初始化时n_iter = 0，迭代一次n_more_iter，更新模型，每次计算loss。 这次不包括验证，但当然您也可以包含验证数据来计算损失。 现在您可以根据历史绘制学习曲线。 如何使用 pyFMGitHub - coreylynch/pyFM: Factorization machines in python 这次使用的图书馆。仅支持回归和分类。 同样，输入作为稀疏矩阵给出。我为获取 Movielens 数据并对其进行处理的部分创建了自己的类。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960import numpy as npimport pandas as pdfrom scipy.sparse import csr_matrixfrom pathlib import Pathimport codecsimport category_encoders as ceclass MovielensLoader: def __init__(self, data_dir=Path(&quot;./ml-100k&quot;), user_filename=&quot;u.user&quot;,item_filename=&quot;u.item&quot;): self.data_dir = data_dir self.user_path = data_dir / user_filename self.item_path = data_dir / item_filename def create_dataset(self, include_user_features=True, include_item_features=True): df_train, y_train = self.load_log_and_ratings(log_filename=&quot;ua.base&quot;) df_test, y_test = self.load_log_and_ratings(log_filename=&quot;ua.test&quot;) target_col = [&quot;uid&quot;, &quot;mid&quot;] if include_user_features: users = self.load_users() target_col = list(set(target_col + users.columns.tolist())) df_train = pd.merge(df_train, users, on=&quot;uid&quot;) df_test = pd.merge(df_test, users, on=&quot;uid&quot;) if include_item_features: items = self.load_items() df_train = pd.merge(df_train, items, on=&quot;mid&quot;) df_test = pd.merge(df_test, items, on=&quot;mid&quot;) self.encoder = ce.OneHotEncoder(cols=target_col) X_train = self.encoder.fit_transform(df_train) X_test = self.encoder.transform(df_test) X_train = csr_matrix(X_train, dtype=np.float) X_test = csr_matrix(X_test, dtype=np.float) return X_train, y_train, X_test, y_test def load_log_and_ratings(self, log_filename, drop_columns=[&quot;timestamp&quot;]): logs = pd.read_csv(self.data_dir / log_filename, names=[&quot;uid&quot;, &quot;mid&quot;, &quot;rating&quot;, &quot;timestamp&quot;], sep=&quot;\\t&quot;, dtype=str) ratings = np.array(logs[&quot;rating&quot;], dtype=np.float) drop_columns.append(&quot;rating&quot;) logs = logs.drop(drop_columns, axis=1) return logs, ratings def load_users(self, drop_columns=[&quot;age&quot;, &quot;zip_code&quot;]): users = pd.read_csv(self.user_path, names=[&quot;uid&quot;, &quot;age&quot;, &quot;gender&quot;, &quot;occupation&quot;, &quot;zip_code&quot;], sep=&quot;|&quot;, dtype=str) users = users.drop(drop_columns, axis=1) return users def load_items(self): with codecs.open(self.item_path, &quot;r&quot;, &quot;Shift-JIS&quot;, &quot;ignore&quot;) as f: items = pd.read_table(f, names=[&quot;mid&quot;, &quot;title&quot;, &quot;released&quot;, &quot;video_released&quot;, &quot;IMDb_URL&quot;, &quot;unknown&quot;, &quot;Action&quot;, &quot;Adventure&quot;, &quot;Animation&quot;, &quot;Children&quot;, &quot;Comedy&quot;, &quot;Crime&quot;, &quot;Documentary&quot;, &quot;Drama&quot;, &quot;Fantasy&quot;, &quot;Film_Noir&quot;, &quot;Horror&quot;, &quot;Musical&quot;, &quot;Mystery&quot;, &quot;Romance&quot;, &quot;Sci_Fi&quot;, &quot;Thriller&quot;, &quot;War&quot;, &quot;Western&quot;], delimiter=&quot;|&quot;, dtype=str) items = items.drop([&quot;title&quot;, &quot;released&quot;, &quot;video_released&quot;, &quot;IMDb_URL&quot;], axis=1) return items 从 MovieLens | GroupLens 下载 Movielens 数据并只准备目录 ./ml-100k。由于 Movielens 在满负荷使用时数据过多，因此发布了各种大小的数据。这次我尝试使用 100k 数据。 Movielens 包含用户附加到项目（电影）的评分数据，每个用户和项目都与一个特征相关联。 用户特征包括年龄、性别、职业，项目特征包括流派。 这一次，我们将使用性别和职业作为用户特征，并使用类型作为项目。 FM 的优点是可以放入这些上下文信息。如果不使用，它将是一个类似于矩阵分解的模型。 这一次，有和没有这些上下文信息 1include_user_features=True, include_item_features=True 我试图通过部分参数来控制。 下面我们进行初始化和学习。 1pylibfm.FM(num_factors=10, num_iter=100, verbose=True, task=&quot;regression&quot;, initial_learning_rate=0.001, learning_rate_schedule=&quot;optimal&quot;) 让我们看看结果。下面，计算测试数据中的RMSE。 12345baseline 1.1220FM 1.1979 (user, itemあり)FM 1.1871 (itemだけ)FM 0.9417 (userだけ)FM 0.9465 (userもitemもなし) 基线是一个不断返回训练数据平均评分的模型。目前，在没有用户和项目的上下文（MF）和用户的附加信息的情况下，RMSE 低于基线，但结果是当包含项目的类型信息时，RMSE 增加。 我还没有调整超参数，所以也许这就是原因。 奖金（其他图书馆）GitHub - jfloff/pywFM: pywFM is a Python wrapper for Steffen Rendle’s factorization machines library libFM FM 作者 Rendle 的官方库 libFM 的 Python 包装器。仅支持回归和分类。 pyfms · PyPI 它是基于 theano 的，但我也发现了类似的东西。很抱歉我没有正确地看到它。 综上所述我尝试使用一次热编码使用 pandas 的 get_dummies 一次，但是如果在测试时出现 train 时不存在的特征，或者相反，如果 train 时存在的某些东西在测试时消失，维度是我不能用的，因为我做不到。 查了一下，Category Encoders 转换类别特征无压力——Qiita 很方便。 不要使用 get_dummies …","link":"/2021/08/12/pyFM-vs-fastFM/"},{"title":"开源软件商用","text":"开源协议是否可以商用（总结） Apache BSD GPL MIT Mozilla 能否商用 Apache Licence是对商业应用友好的许可。使用者也可以在需要的时候修改代码来满足需要并作为开源或商业产品发布/销售。 商业软件可以使用，也可以修改使用BSD协议的代码。 商业软件不能使用GPL协议的代码。 商业软件可以使用，也可以修改MIT协议的代码，甚至可以出售MIT协议的代码。 商业软件可以使用，也可以修改MPL协议的代码，但修改后的代码版权归软件的发起者。 其他参考","link":"/2021/09/03/%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E5%95%86%E7%94%A8/"},{"title":"打不开 leetcode-cn.com","text":"Solution1ping leetcode-cn.com 无法ping通打开常用域名解析地址文件 /ect/hosts删除 leetcode-cn.com 这一行","link":"/2021/10/05/%E6%89%93%E4%B8%8D%E5%BC%80leetcode-cn-com/"},{"title":"枚举所有子集","text":"Problem 枚举全集的所有子集枚举数组 $a={1,2,3,6}$的所有子集 解答 solution构建 $[0, 2^n]$ 到 $a$ 的所有子集的双射从 0000 枚举到 1111 代码 code123int n = a.size()for (int i = 0; i &lt; (1 &lt;&lt; n); ++i) {} Problem 枚举非全集的所有子集三个字符串 A=’abd’, B=’be’, C=’df’枚举每个字符串的所有子集 解答 solution构建二进制表示 A=001011, B=010010, C=101000对于A的所有子集，subset从A开始枚举，然后迭代subset -= 1，然后限制在A空间上 subset &amp;= A 即 subset = (subset - 1) &amp; A变换前后subset在A空间上至多相差1，因为它们在全空间上相差1，也就是说变换前后subset在A空间上要么相等要么相邻由于每个subset在A空间之外的分量都是0然后嵌入到全空间上，subset-1必然导致subset在A空间上发生改变，所以变换前后subset在A空间上是相邻的，这样就完成了对非全空间A的所有子集的顺序遍历 代码 code123for (int subset = A; subset; ) { subset = (subset - 1) &amp; A;}","link":"/2021/02/26/%E6%9E%9A%E4%B8%BE%E6%89%80%E6%9C%89%E5%AD%90%E9%9B%86/"},{"title":"物料智能编码","text":"背景 Why物料编码是 ERP 信息化的一个基本问题。物料具有多种属性，不同的物料其名称可能是相同的，不能仅根据物料名称来区分不同物料，需要给每种物料一个唯一的编码。对物料进行编码的过程中，由于存在地区时间的差异等因素，会出现一种物料多个编码的情况，这就容易造成物资积压、调度性差、资源浪费等问题。因此我们需要一个便于录入读取并且易于扩展的物料编码解决方案。 问题描述 What对于多种（可能高达数十万种）物料，并且物料的种类可能随着时间不断增加，如何给每种物料一个编码，要求： 每种物料的编码唯一，且一旦确定就不再更改 给定一个编码，相关工作人员不需查询就容易知道是何种物料 给定一个物料，可以知道其编码是否已经存在 给定一个物料，若其编码已经存在，相关工作人员不需查询就容易知道其编码 案例 Example由于原始数据难以脱敏，现以三国人物作为物料 数据 data 姓名 表字 势力 武力 统帅 智力 内政 外交 魅力 忠诚 武器 坐骑 技能 曹操 孟德 魏 70 90 75 80 70 90 60 青釭剑 绝影 奸雄 诸葛亮 孔明 蜀 65 92 96 99 98 95 95 朱雀羽扇 木牛流马 八阵 关羽 云长 蜀 98 95 85 60 50 95 98 青龙偃月刀 赤兔 武圣 刘备 玄德 蜀 75 80 75 75 70 98 80 雌雄双股剑 的卢 仁德 张飞 翼德 蜀 97 80 80 50 60 75 98 丈八蛇矛 无 咆哮 吕布 奉先 群 100 75 50 50 60 70 30 方天画戟 赤兔 无双 董卓 仲颖 群 80 80 65 60 70 60 40 无 赤兔 暴虐 司马懿 仲达 魏 80 90 90 90 80 80 65 无 无 天命 孙权 仲谋 吴 70 85 75 80 70 85 65 吴六剑 无 制衡 周瑜 公瑾 吴 85 95 85 75 75 80 90 无 无 英姿 袁绍 本初 群 70 75 70 70 60 85 80 无 无 名门 张角 无 群 70 80 80 70 55 90 50 无 无 黄天 司马昭 子尚 晋 80 90 85 80 80 75 50 无 无 昭心 贾诩 文和 群 65 65 97 85 85 75 70 无 无 毒士 贾诩 文和 魏 65 65 97 85 85 75 90 无 无 毒士 荀彧 文若 魏 65 65 96 96 80 90 95 无 无 节命 荀攸 公达 魏 65 65 99 80 75 80 90 无 无 奇策 郭嘉 奉孝 魏 60 65 98 90 90 90 95 无 无 天妒 程昱 仲德 魏 85 85 92 80 70 70 90 无 无 设伏 姜维 伯约 蜀 88 90 92 88 80 85 95 无 无 志继 姜维 伯约 魏 88 90 92 80 75 80 75 无 无 挑衅 鲁肃 子敬 吴 70 80 90 80 95 75 90 无 无 缔盟 吕蒙 子明 吴 80 90 90 75 60 75 90 无 无 博学 陆逊 伯言 吴 70 90 92 75 70 80 90 无 无 连营 孙坚 文台 吴 95 90 80 70 70 90 80 古锭刀 无 英魂 许褚 仲康 魏 97 80 60 50 50 75 90 贯石斧 无 裸衣 典韦 无 魏 99 65 55 50 50 75 95 双戟 无 强袭 黄忠 汉升 蜀 95 80 75 60 60 70 85 麒麟弓 无 烈弓 马超 孟起 群 97 85 70 70 70 80 80 无 无 铁骑 马超 孟起 蜀 97 85 70 70 70 80 80 无 无 铁骑 赵云 子龙 蜀 96 70 75 70 70 90 95 银月霸王枪 无 龙胆 魏延 文长 蜀 93 80 82 70 60 65 85 无 无 狂骨 法正 孝直 蜀 74 79 97 74 69 88 95 无 无 恩怨 庞统 士元 蜀 65 65 96 90 90 75 90 无 无 涅槃 孙策 伯符 吴 94 90 65 70 70 90 80 无 无 激昂 太史慈 子义 吴 94 85 75 65 65 90 90 无 无 天义 甘宁 兴霸 吴 94 85 80 65 65 75 90 无 无 奇袭 张辽 文远 魏 93 85 80 65 70 85 85 无 无 突袭 徐晃 公明 魏 90 85 85 65 65 85 90 无 无 断粮 夏侯惇 元让 魏 94 88 70 65 65 88 95 无 无 刚烈 庞德 令明 魏 94 85 70 65 65 85 90 无 无 猛进 曹纯 子和 魏 70 75 75 70 65 80 95 无 无 缮甲 初步编码 tentative给每个人物唯一一个编码 外部环境规定每个属性的重要性，不同属性的重要性可以相同0 姓名 1 表字 势力 武器 坐骑 技能 2 武力 统帅 智力 内政 外交 魅力 忠诚 对于非数值型属性，重要性相同的属性按照信息熵由小到大排列0 姓名 1 势力 2 坐骑 3 武器 4 表字 5 技能 对于数值型属性，除非外部环境规定，一般不纳入编码规定加入 6 武力 7 智力 非数值型属性之间以拼音首字母(为了区分度可能增加至多个)大小写分割，数值型属性都用两位数字表示 编码 姓名 势力 坐骑 武器 表字 技能 武力 智力 CCweJYqgjMDjx7075 曹操 魏 绝影 青釭剑 孟德 奸雄 70 75 ZGLsMNLMzqysKMbz6596 诸葛亮 蜀 木牛流马 朱雀羽扇 孔明 八阵 65 96 GYsCTqlyydYCws9885 关羽 蜀 赤兔 青龙偃月刀 云长 武圣 98 85 优化后的编码 optimize 某些属性与主要属性的交叉熵比较大，去掉这些冗余的属性 信息熵较小且重要性较大的属性放在最前面便于分类 编码 姓名 势力 武力 智力 Ecc7075 曹操 魏 70 75 Szgl6596 诸葛亮 蜀 65 96 Sgy9885 关羽 蜀 98 85 Slb7575 刘备 蜀 75 75 Szf9780 张飞 蜀 97 80 Qlb0050 吕布 群 100 50 Qdz8065 董卓 群 80 65 Esmy8090 司马懿 魏 80 90 Usq7075 孙权 吴 70 75 Uzy8585 周瑜 吴 85 85 Qys7070 袁绍 群 70 70 Qzj7080 张角 群 70 80 Jsmz8085 司马昭 晋 80 85 Qjx6597 贾诩 群 65 97 Ejx6597 贾诩 魏 65 97 Exy6596 荀彧 魏 65 96 Exy6599 荀攸 魏 65 99 Egj6098 郭嘉 魏 60 98 Ecy8592 程昱 魏 85 92 Sjw8892 姜维 蜀 88 92 Ejw8892 姜维 魏 88 92 Uls7090 鲁肃 吴 70 90 Ulm8090 吕蒙 吴 80 90 Ulx7092 陆逊 吴 70 92 Usj9580 孙坚 吴 95 80 Exc9760 许褚 魏 97 60 Edw9955 典韦 魏 99 55 Shz9575 黄忠 蜀 95 75 Qmc9770 马超 群 97 70 Smc9770 马超 蜀 97 70 Szy9675 赵云 蜀 96 75 Swy9382 魏延 蜀 93 82 Sfz7497 法正 蜀 74 97 Spt6596 庞统 蜀 65 96 Usc9465 孙策 吴 94 65 Utsc9475 太史慈 吴 94 75 Ugn9480 甘宁 吴 94 80 Ezl9380 张辽 魏 93 80 Exh9085 徐晃 魏 90 85 Exhd9470 夏侯惇 魏 94 70 Epd9470 庞德 魏 94 70 Ecc7075zh 曹纯 魏 70 75 编码的可扩展性 scalability 每当产生冲突时，已经编码的物料其编码保持不变 对新添加的物料编码增加维度，优先选择信息熵较大的非数值型属性，综合考虑重要性、复杂度 姓名 表字 势力 武力 统帅 智力 内政 外交 魅力 忠诚 武器 坐骑 技能 曹操 孟德 魏 70 90 75 80 70 90 60 青釭剑 绝影 奸雄 曹纯 子和 魏 70 75 75 70 65 80 95 无 无 缮甲 编码 姓名 势力 武力 智力 表字 Ecc7075 曹操 魏 70 75 Ecc7075zh 曹纯 魏 70 75 子和 解决方案 How","link":"/2021/02/02/%E7%89%A9%E6%96%99%E6%99%BA%E8%83%BD%E7%BC%96%E7%A0%81/"},{"title":"Gecko Roaming the Wall, the 6th Level of Nine-Yang-Divine-Skill, for Network-Max-Flow","text":"网络最大流之九阳神功第六层「壁虎游墙」 Preface 前言It’s a ridge viewing from a horizontal perspective, while a peak from otherwise, with distinct distances and heights. To comprehend the nature of Network-Max-Flow, it’s required to observe it from various perspectives. Therefore, gecko roaming the wall, the 6th level of Nine-Yang-Divine-Skill, will continue to discuss theoretical problems. 横看成岭侧成峰，远近高低各不同。 欲识庐山真面目，就需要从各个角度去观察网络最大流。 所以九阳神功第六层「壁虎游墙」继续讨论理论问题。 Convergence Condition 算法收敛条件Augmenting-Path 提升路$G=(V,A,~\\mathcal{C})$ is a network,where $\\mathcal{C}:A\\longrightarrow\\mathbb{R}$ unless otherwise regulated.$P$ is an $s,t$ path of $G$.$f:A\\longrightarrow\\mathbb{R}$ is a flow of $G$.$r=\\mathcal{C}-f$ is the residual of $G$ with respect to $f$.Then $P$ is called an augmenting-path of $G$,if $r(a)&gt;0$ for any arc $a\\in A(P)$. Theorem0 定理0Alias of Convergence Condition Theorem. For any algorithm based on augmenting-paths, it’s always provided that: the network contains no augmenting-paths when the algorithm terminates. We’ll prove Theorem7 of the 5th level of Nine-Yang-Divine-Skill in the following pipeline. $\\underline{\\textbf{Theorem0}}$$f$ is a max-flow of $G$ iff $G$ contains no augmenting-paths. $\\textbf{proof:}$$”\\Longrightarrow”$ Obviously. If not, $f$ will be augmented.$”\\Longleftarrow”$ By Lemma2 there exists a cut $(S,\\bar S)$ s.t. $r(S,\\bar S)=0$. By Lemma3 of the 5th Level of Nine-Yang-Divine-Skill, $f$ is a max-flow.$\\square$ Lemma1 引理1Let $\\mathcal{P}(G)$ be the set of all $s,t$ paths of $G$, i.e. $\\mathcal{P}(G)=\\lbrace P:~P\\text{ is an }s,t\\text{ path of }G\\rbrace$. $\\underline{\\textbf{Lemma1}}$$G$ contains no augmenting-paths iff for any $P\\in\\mathcal{P}(G)$ there exists $a\\in A(P)$ s.t. $r(a)=0$. $\\textbf{proof:}$$”\\Longrightarrow”$ If not, there exists $P\\in\\mathcal{P}(G)$ s.t. for all $a\\in A(P):~r(a)\\neq0$. By $f$’s property (i) Bound, we have $r(a)&gt;0$. This means $P$ is an augmenting-path, violating that $G$ contains no augmenting-paths.$”\\Longleftarrow”$ Similarly using proof by contradiction.$\\square$ Lemma2 引理2Let $Q$ be a path starting with $s$ but not containing $t$. $Q$ is called an s-partial-augmenting-path(SPAP) of $G$, if $r(a)&gt;0$ for any arc $a\\in A(Q)$. Let $\\mathcal{Q}(G)=\\lbrace Q:~Q\\text{ is an SPAP of }G\\rbrace$. Let $V(\\mathcal{Q})=\\bigcup\\limits_{Q\\in\\mathcal{Q}(G)}V(Q)$. $\\underline{\\textbf{Lemma2}}$$G$ contains no augmenting-paths iff there exists a cut $(S,\\bar S)$ s.t. $r(S,\\bar S)=0$. $\\textbf{proof:}$$”\\Longleftarrow”$ $r(S,\\bar S)=0$ is equivalent to $r(a)=0,\\text{ }\\forall\\text{ }a\\in(S,\\bar S)$.By Lemma6, any $s,t$ path $P$ meets $(S,\\bar S)$ at $a\\in A(P)\\cap(S,\\bar S)$ with $r(a)=0$,indicating that $P$ isn’t an augmenting-path by Lemma1.$”\\Longrightarrow”$ Let $S=V(\\mathcal{Q})$ and we’ve done.It suffices to show $r(a)=0,\\text{ }\\forall\\text{ }a\\in(S,\\bar S)$.Suppose to the contrary that $\\exists\\text{ }a=(x,y)\\in(S,\\bar S)\\text{ s.t. }r(a)\\neq0$.By the definition of $V(\\mathcal{Q})$, there exists $Q\\in\\mathcal{Q}(G)$s.t. $x$ is a vertex, particularly the last vertex of $Q$.Since $r(a)&gt;0$, then the extended path $Qy\\in\\mathcal{Q}(G)$, violating that $y\\in\\bar S$.$\\square$ Corollary3 推论3If the loop of the algorithm is executed in finite steps,we call the algorithm terminates. $\\underline{\\textbf{Corollary3}}$If the algorithm terminates, then it outputs a max-flow of the network. $\\textbf{proof:}$The condition the algorithm terminates implies the network contains no augmenting-paths.The result follows by Theorem0.$\\square$ Is there any case in which the algorithm doesn’t terminate? Theorem4 定理4Next we’ll prove Lemma6 of the 5th Level of Nine-Yang-Divine-Skill in the following pipeline. $\\underline{\\textbf{Theorem4}}$If $\\mathcal{C}:A\\longrightarrow\\mathbb{Q}$ and $f:A\\longrightarrow\\mathbb{Q}$, then the algorithm terminates. $\\textbf{proof:}$For any $a_i\\in A$, let $\\mathcal{C}(a_i)=\\frac{x_i}{y_i}$ and $f(a_i)=\\frac{z_i}{w_i}$,where $x_i,y_i,z_i,w_i\\in\\mathbb{N}$ and $(x_i,y_i)=1,~(z_i,w_i)=1$.Let $M=\\prod\\limits_{i:a_i\\in A}y_iw_i$. Let $\\mathcal{C}’=M\\cdot\\mathcal{C}$ and $f’=M\\cdot f$.It’s easy to see $\\mathcal{C}’,f’$ are natural numbers.Applying Theorem5 to $\\mathcal{C}’,f’$ we’ve done.$\\square$ Theorem5 定理5$\\underline{\\textbf{Theorem5}}$If $\\mathcal{C}:A\\longrightarrow\\mathbb{N}$ and $f:A\\longrightarrow\\mathbb{N}$, then the algorithm terminates. $\\textbf{proof:}$Suppose to the contrary that the algorithm doesn’t terminate.Let $\\lbrace f_i\\rbrace_{i=0}^\\infty$ be the progression of flows generated by the algorithm.On one hand, since $\\mathcal{C},f$ is constrained from $\\mathbb{R}$ to $\\mathbb{N}$,then $\\vert f_i\\vert+1\\leq\\vert f_{i+1}\\vert,\\text{ }\\forall\\text{ }i\\in\\mathbb{N}$,which leads to $\\lim\\limits_{i\\to\\infty}\\vert f_i\\vert=\\infty$,meaning that the progression is unbounded.On the other hand, by Lemma1 and Lemma2 of the 5th Level of Nine-Yang-Divine-Skill, $\\vert f_i\\vert\\leq\\mathcal{C}(t_*),\\text{ }\\forall\\text{ }i\\in\\mathbb{N}$,meaning that the progression is upper-bounded by the capacity of the minimal cut, which is a contradiction.$\\square$ Lemma6 引理6This lemma asserts that an $s,t$ path ought to meet any cut of the network. $\\underline{\\textbf{Lemma6}}$Let $(S,\\bar S)$ be any cut, and $P$ be any $s,t$ path, of $G$. Then $A(P)\\cap(S,\\bar S)\\neq\\varnothing$. $\\textbf{proof:}$Let $P=v_0v_1\\cdots v_l$ with $v_0=s$ and $v_l=t$.Noting that $s\\in S$ and $t\\in\\bar S$,there exists a minimal index $i\\in\\lbrace1,2,\\cdots,l\\rbrace$ satisfying $v_i\\in\\bar S$,hence $(v_{i-1},v_i)\\in(S,\\bar S)$.$\\square$ Path Flow Decomposition 路径流量分解We’nna prove the theorem of the 4th Level of Nine-Yang-Divine-Skill in the following pipeline. Path Flow 路径流量$P$ is an $s,t$ path of $G$.$f$ is a flow of $G$.Then $f$ is called a path-flow of $G$,if $f(a)=C,\\text{ }\\forall\\text{ }a\\in A(P)$ for some constant $C\\in\\mathbb{R}$,and $f(a)=0,\\text{ }\\forall\\text{ }a\\in A\\setminus A(P)$. Let $f_P$ denote a flow satisfyingif $a\\in A(P)$, then $f_P(a)=1$;otherwise $f_P(a)=0$. Cycle Flow 环流$C$ is a cycle of $G$.$f$ is a flow of $G$.Then $f$ is called a cycle-flow of $G$,if $f(a)=T,\\text{ }\\forall\\text{ }a\\in A(C)$ for some constant $T\\in\\mathbb{R}$,and $f(a)=0,\\text{ }\\forall\\text{ }a\\in A\\setminus A(C)$. Theorem7 定理7Alias of Path Flow Decomposition Theorem. For capacity $\\mathcal{C}:A\\longrightarrow\\mathbb{R}$ and flow $f:A\\longrightarrow\\mathbb{R}$,we define an assignment operation from $f$ to $\\mathcal{C}$:$\\mathcal{C}\\leftarrow f$ as $\\forall\\text{ }(u,v)\\in A$,let $\\mathcal{C}(u,v)=\\mathcal{C}(v,u)=\\max\\lbrace f(u,v),f(v,u)\\rbrace$. We define a partial-order on flows:for $f,g\\in\\mathcal{F}(G)$, we say $f&lt;g$,if $f(u,v)\\leq g(u,v),\\text{ }\\forall\\text{ }(u,v)\\in A$,and $\\exists\\text{ }(u,v)\\in A\\text{ s.t. }f(u,v)&lt;g(u,v)$. We define an equivalent-relationship on flows:for $f,g\\in\\mathcal{F}(G)$, we say $f\\equiv g$,if $f,g$ differ by several cycle-flows. $\\underline{\\textbf{Theorem7}}$For any flow $f$ of $G$, there exists a progression $\\lbrace f_i\\rbrace_{i=1}^\\infty$ of path-flows of $G$s.t. $f=\\sum\\limits_{i=1}^\\infty f_i$. $\\textbf{proof:}$Let network $G’=(V,A,\\mathcal{C}’)$ with $\\mathcal{C}’\\longleftarrow f$,and obviously $f$ is a max-flow of $G’$.Let $f_0$ be the 0-flow of $G’$.Let $F_i=\\sum\\limits_{j=0}^if_j,\\text{ }\\forall\\text{ }i\\in\\mathbb{N}$.If there exists an augmenting-path $P_i$ of $G’$ with respect to $F_i$,which can be determined in polynomial time by some search method,let $f_{i+1}=\\delta\\cdot f_{P_i}$ with $\\delta=\\min\\limits_{a\\in A(P_i)}r(a)$;Otherwise let $f_{i+1}=f_{i+2}=\\cdots=0$,in which case obviously $f=F_i$ holds by Theorem0.It suffices to show $\\lim\\limits_{i\\to\\infty}F_i=f$,in the case that for every $F_i$ there exists $P_i$.Noting that $F_i&lt;F_{i+1}&lt;f,\\text{ }\\forall\\text{ }i\\in\\mathbb{N}$,then for every $(u,v)\\in A$ the progression $\\lbrace F_i(u,v)\\rbrace_{i=0}^\\infty$ converges.So let $\\lim\\limits_{i\\to\\infty}F_i=f’$ where $f’\\leq f$.Suppose to the contrary that $\\exists\\text{ }(u,v)\\in A$ satisfying $\\lim\\limits_{i\\to\\infty}F_i(u,v)=f’(u,v)&lt;f(u,v)$.If there exists no augmenting-paths containing $(u,v)$ with respect to $f’$,then $(u,v)$ is contained by several cycle-flows of $f-f’$,thus by Lemma8 $f’$ can be expressed as $\\sum\\limits_{i=1}^\\infty g_i$;Otherwise $\\exists P$ containing $(u,v)$ w.r.t. $f’$,let $\\delta=\\min\\limits_{a\\in A(P)}(f-f’)(u,v)$ and $g=f’+\\delta*f_P$,violating that $f’$ is the summation of all the $f_P$ s.$\\square$ Lemma8 引理8$\\underline{\\textbf{Lemma8}}$For any $f,g\\in\\mathcal{F}(G)$ satisfying $f\\equiv g$,if $f=\\sum\\limits_{i=1}^\\infty f_i$ for some progression $\\lbrace f_i\\rbrace_{i=1}^\\infty$ of flows of $G$,then $g=\\sum\\limits_{i=1}^\\infty g_i$ for some progression $\\lbrace g_i\\rbrace_{i=1}^\\infty$ of flows of $G$. $\\textbf{proof:}$Noting that a cycle-flow is a flow,and $f,g$ differ by several cycle-flows.$\\square$ Summary 小结This post demonstrates Convergence Condition Theorem of algorithms based on augmenting-paths technique. Also it demonstrates Path Flow Decomposition Theorem. Reference 参考 Purple Qi of the Rich Mist, the 1st Level of Nine-Yang-Divine-Skill, for Network-Max-Flow, 网络最大流之九阳神功第一层「氤氲紫气」 Tendon Changing and Marrow Cleansing, the 2nd Level of Nine-Yang-Divine-Skill, for Network-Max-Flow, 网络最大流之九阳神功第二层「易筋洗髓」 Fiery Qi of the Ultimate Yang, the 3rd Level of Nine-Yang-Divine-Skill, for Network-Max-Flow, 网络最大流之九阳神功第三层「至阳热气」 Bone Shrinking Technique, the 4th Level of Nine-Yang-Divine-Skill, for Network-Max-Flow, 网络最大流之九阳神功第四层「缩骨大法」 Turtle Breathing Technique, the 5th Level of Nine-Yang-Divine-Skill, for Network-Max-Flow, 网络最大流之九阳神功第五层「龟息大法」 Gecko Roaming the Wall, the 6th Level of Nine-Yang-Divine-Skill, for Network-Max-Flow, 网络最大流之九阳神功第六层「壁虎游墙」 Immunity to All Positions, the 7th Level of Nine-Yang-Divine-Skill, for Network-Max-Flow, 网络最大流之九阳神功第七层「诸毒不侵」 Indestructible Vajra Body, the 8th Level of Nine-Yang-Divine-Skill, for Network-Max-Flow, 网络最大流之九阳神功第八层「金刚不坏」 Rebound Attack, the 9th Level of Nine-Yang-Divine-Skill, for Network-Max-Flow, 网络最大流之九阳神功第九层「反弹攻击」 Stronger with Each Use, the 10th Level of Nine-Yang-Divine-Skill, for Network-Max-Flow, 网络最大流之九阳神功第十层「愈使愈强」","link":"/2024/03/01/%E7%BD%91%E7%BB%9C%E6%9C%80%E5%A4%A7%E6%B5%81%E4%B9%8B%E4%B9%9D%E9%98%B3%E7%A5%9E%E5%8A%9F%E7%AC%AC%E5%85%AD%E5%B1%82%E3%80%8C%E5%A3%81%E8%99%8E%E6%B8%B8%E5%A2%99%E3%80%8D/"},{"title":"Immunity to All Poisons, the 7th Level of Nine-Yang-Divine-Skill, for Network-Max-Flow","text":"网络最大流之九阳神功第七层「诸毒不侵」 Preface 前言The mechanic who wished to do his work well,must first sharpen his tools. Solving the basic theoretical problems,the 7th level of Nine-Yang-Divine-Skill,goes back to algorithmic problems again. 工欲善其事必先利其器， 解决了基本理论问题， 九阳神功第七层「诸毒不侵」再次回到算法问题。 Shortest Augmenting Path Algorithm 最短提升路算法Pseudo Code 伪代码123456789101112131415161718192021222324252627282930313233343536ALGORITHM ShortestAugmentingPath;BEGIN F := 0; init distance function D; init predecessor function Pred; v := s; WHILE D(s) &lt; n DO BEGIN IF v has an admissible arc THEN BEGIN Advance(v); if v == t then Augment() and v := s; END ELSE Retreat(v); ENDENDFUNCTION Advance(v);BEGIN get an admissible arc (v,w); Pred(w) := v; v := w;ENDFUNCTION Retreat(v);BEGIN D(v) := min{D(u)+1 : (u,v) in A, r(u,v)&gt;0}; IF v != s THEN v := Pred(v);ENDFUNCTION Augment;BEGIN P := the admissible augmenting path from s to t; delta := min{r(u,v) : (u,v) in A(P)}; augment delta units of flow F along path P;END Concept 概念$G=(V,A,\\mathcal{C})$ is the network. DistanceLet $\\mathfrak{D}(v)$ be the distance of $v\\in V$ to $t$. Quasi-DistanceLet $D:V\\longrightarrow\\mathbb{N}$ be the quasi-distance functionsatifying $D(t)=0$ and $D(u)\\leq D(v)+1,\\text{ }\\forall\\text{ }(u,v)\\in A$. AdmissibleAn arc $(u,v)\\in A$ is called admissible if $D(u)=D(v)+1$. An $s,t$ path $P$ is called admissible if every arc of $P$ is admissible. Lemma 引理$\\underline{\\textbf{Lemma0}}$For any arc $(u,v)$ of any $s,t$ path $P$,it holds $\\mathfrak{D}(u)\\leq\\mathfrak{D}(v)+1$.So $\\mathfrak{D}$ is a quasi-distance. $\\textbf{proof:}$Let $Q$ be a shortest path from $v$ to $t$.Then the extended path $(u,v)Q$ is a path from $u$ to $t$,Thus leading to $\\mathfrak{D}(u)\\leq\\vert(u,v)Q\\vert=1+\\mathfrak{D}(v)$. Summary 小结Reference 参考 Purple Qi of the Rich Mist, the 1st Level of Nine-Yang-Divine-Skill, for Network-Max-Flow, 网络最大流之九阳神功第一层「氤氲紫气」 Tendon Changing and Marrow Cleansing, the 2nd Level of Nine-Yang-Divine-Skill, for Network-Max-Flow, 网络最大流之九阳神功第二层「易筋洗髓」 Fiery Qi of the Ultimate Yang, the 3rd Level of Nine-Yang-Divine-Skill, for Network-Max-Flow, 网络最大流之九阳神功第三层「至阳热气」 Bone Shrinking Technique, the 4th Level of Nine-Yang-Divine-Skill, for Network-Max-Flow, 网络最大流之九阳神功第四层「缩骨大法」 Turtle Breathing Technique, the 5th Level of Nine-Yang-Divine-Skill, for Network-Max-Flow, 网络最大流之九阳神功第五层「龟息大法」 Gecko Roaming the Wall, the 6th Level of Nine-Yang-Divine-Skill, for Network-Max-Flow, 网络最大流之九阳神功第六层「壁虎游墙」 Immunity to All Positions, the 7th Level of Nine-Yang-Divine-Skill, for Network-Max-Flow, 网络最大流之九阳神功第七层「诸毒不侵」 Indestructible Vajra Body, the 8th Level of Nine-Yang-Divine-Skill, for Network-Max-Flow, 网络最大流之九阳神功第八层「金刚不坏」 Rebound Attack, the 9th Level of Nine-Yang-Divine-Skill, for Network-Max-Flow, 网络最大流之九阳神功第九层「反弹攻击」 Stronger with Each Use, the 10th Level of Nine-Yang-Divine-Skill, for Network-Max-Flow, 网络最大流之九阳神功第十层「愈使愈强」","link":"/2024/03/06/%E7%BD%91%E7%BB%9C%E6%9C%80%E5%A4%A7%E6%B5%81%E4%B9%8B%E4%B9%9D%E9%98%B3%E7%A5%9E%E5%8A%9F%E7%AC%AC%E4%B8%83%E5%B1%82%E3%80%8C%E8%AF%B8%E6%AF%92%E4%B8%8D%E4%BE%B5%E3%80%8D/"},{"title":"跑步","text":"0跟着180节奏音乐 1腹部绷紧找不到感觉=&gt; 肩背向下后方发力，腹部发力与之对抗 2前2公里中频小碎步热身 3腹部持续中度绷紧，其他部位放松，减少能耗 4最小化冗余动作和上下左右震动，减少能耗 5脚步落地一瞬，腹部增加发力形成支点，腿部借助势能微微发力迅速转化为前进动能 6呼气时腹部微微发力内卷，吸气时腹部自动还原至水平，肩背微微向后下方发力，两大臂自然向后夹住两肋，保持上身稳定 7落脚与大地融合，呼吸共长天一气 8跑量超标导致小腿内侧筋膜疼痛=&gt;弹力球按压恢复","link":"/2021/08/07/%E8%B7%91%E6%AD%A5/"}],"tags":[{"name":"Mac","slug":"Mac","link":"/tags/Mac/"},{"name":"homebrew","slug":"homebrew","link":"/tags/homebrew/"},{"name":"qita","slug":"qita","link":"/tags/qita/"},{"name":"CSDN","slug":"CSDN","link":"/tags/CSDN/"},{"name":"stackoverflow","slug":"stackoverflow","link":"/tags/stackoverflow/"},{"name":"DeepFM","slug":"DeepFM","link":"/tags/DeepFM/"},{"name":"Github","slug":"Github","link":"/tags/Github/"},{"name":"Tensorflow","slug":"Tensorflow","link":"/tags/Tensorflow/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"kaggle","slug":"kaggle","link":"/tags/kaggle/"},{"name":"FM","slug":"FM","link":"/tags/FM/"},{"name":"ML","slug":"ML","link":"/tags/ML/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"Kruskal","slug":"Kruskal","link":"/tags/Kruskal/"},{"name":"algorithm","slug":"algorithm","link":"/tags/algorithm/"},{"name":"LeetCode","slug":"LeetCode","link":"/tags/LeetCode/"},{"name":"Manim","slug":"Manim","link":"/tags/Manim/"},{"name":"hive","slug":"hive","link":"/tags/hive/"},{"name":"sql","slug":"sql","link":"/tags/sql/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"feature","slug":"feature","link":"/tags/feature/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"Icarus","slug":"Icarus","link":"/tags/Icarus/"},{"name":"WordPress","slug":"WordPress","link":"/tags/WordPress/"},{"name":"Google","slug":"Google","link":"/tags/Google/"},{"name":"Spark","slug":"Spark","link":"/tags/Spark/"},{"name":"SQL","slug":"SQL","link":"/tags/SQL/"},{"name":"召回","slug":"召回","link":"/tags/%E5%8F%AC%E5%9B%9E/"},{"name":"推荐系统","slug":"推荐系统","link":"/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"},{"name":"Tao","slug":"Tao","link":"/tags/Tao/"},{"name":"并查集","slug":"并查集","link":"/tags/%E5%B9%B6%E6%9F%A5%E9%9B%86/"},{"name":"洛谷","slug":"洛谷","link":"/tags/%E6%B4%9B%E8%B0%B7/"},{"name":"StackOverflow","slug":"StackOverflow","link":"/tags/StackOverflow/"},{"name":"macOS","slug":"macOS","link":"/tags/macOS/"},{"name":"file","slug":"file","link":"/tags/file/"},{"name":"model","slug":"model","link":"/tags/model/"},{"name":"encoding","slug":"encoding","link":"/tags/encoding/"},{"name":"tkinter","slug":"tkinter","link":"/tags/tkinter/"},{"name":"subset","slug":"subset","link":"/tags/subset/"},{"name":"space","slug":"space","link":"/tags/space/"},{"name":"ERP","slug":"ERP","link":"/tags/ERP/"},{"name":"三国","slug":"三国","link":"/tags/%E4%B8%89%E5%9B%BD/"},{"name":"九阳神功","slug":"九阳神功","link":"/tags/%E4%B9%9D%E9%98%B3%E7%A5%9E%E5%8A%9F/"},{"name":"Nine-Yang-Divine-Skill","slug":"Nine-Yang-Divine-Skill","link":"/tags/Nine-Yang-Divine-Skill/"},{"name":"网络最大流","slug":"网络最大流","link":"/tags/%E7%BD%91%E7%BB%9C%E6%9C%80%E5%A4%A7%E6%B5%81/"},{"name":"Network-Max-Flow","slug":"Network-Max-Flow","link":"/tags/Network-Max-Flow/"},{"name":"running","slug":"running","link":"/tags/running/"}],"categories":[{"name":"深度学习","slug":"深度学习","link":"/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"机器学习","slug":"机器学习","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"数据结构&amp;算法","slug":"数据结构-算法","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%AE%97%E6%B3%95/"},{"name":"debug","slug":"debug","link":"/categories/debug/"},{"name":"推荐系统","slug":"机器学习/推荐系统","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"},{"name":"博客","slug":"博客","link":"/categories/%E5%8D%9A%E5%AE%A2/"},{"name":"操作系统","slug":"操作系统","link":"/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"jupyter","slug":"jupyter","link":"/categories/jupyter/"},{"name":"数学","slug":"数学","link":"/categories/%E6%95%B0%E5%AD%A6/"},{"name":"工程项目","slug":"工程项目","link":"/categories/%E5%B7%A5%E7%A8%8B%E9%A1%B9%E7%9B%AE/"},{"name":"图论","slug":"数学/图论","link":"/categories/%E6%95%B0%E5%AD%A6/%E5%9B%BE%E8%AE%BA/"}]}