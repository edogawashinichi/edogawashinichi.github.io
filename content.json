{"pages":[],"posts":[{"title":"Brew Install 报错","text":"Problem123$ brew updatefatal: gitError: another SolutionqitaCSDNstackoverflow","link":"/2021/03/26/Brew-Install-%E6%8A%A5%E9%94%99/"},{"title":"Brooks Theorem","text":"Lemma$\\chi(G)\\leq\\Delta(G)+1$,that is:the chromatic number is no more thanthe maximum degree plus one. HINT:第一感是这个结论不平凡，$\\Delta(G)+1$种颜色local满足每个点的闭邻域，但如何保证global不会产生矛盾？给每个闭邻域规定一个量子态$c(N[v])\\sim U\\binom{[\\Delta+1]}{d(v)+1}$，即每个闭邻域的染色方案等概率取自$\\binom{[\\Delta+1]}{d(v)+1}$，让每个闭邻域的量子态坍缩（若两个闭邻域坍缩导致同一个点颜色不同则得到的染色方案非法）这样得到的染色方案是否有一定概率是合法的难以决断。给每个点规定一个量子态$c(v)\\sim U\\binom{[\\Delta+1]}{1}$，即每个点的染色方案等概率取自$\\binom{[\\Delta+1]}{1}$，让每个点的量子态坍缩，这样得到的染色方案必然有一定概率是合法的，只需让所有点按照任意次序坍缩并始终维护合法状态。$\\bigstar$ PROOF:Let $\\sigma=[v_1,v_2,\\cdots,v_n]$ be any ordering of $V(G)$.Color $V(G)$ with $\\Delta(G)+1$ colors in ordering $\\sigma$,and we’ve done, since the $\\Delta(G)+1$ colors sufficeevery closed neighbors $N[v]$ for any $v\\in V(G)$, and $V(G)$ is a finite set.$\\square$ Theorem (Brooks, 1941)$G$ is a connected graph.$\\chi(G)=\\Delta(G)+1$,iff (if and only if),$G$ is either a complete graph,or an odd cycle. (version1)Or equivalently,$G$ is neither a complete graph,nor an odd cycle,iff $\\chi(G)\\leq\\Delta(G)$. (version2) PROOF:We’ll prove version1 or version2 in 5 cases.Case I: $\\Delta=0\\text{ or }1$;$~~~~G$ is a single vertex or two connected vertices,$~~~~$proving version1.Case II: $\\Delta=2$;$~~~~G$ is either a path or an odd cycle,$~~~~$proving version2 and version1 respectively.Case III: $\\Delta\\geq3$ and $G$ is irregular;$~~~~$Then there exists a vertex $v\\in V$$~~~~$such that $d(v)&lt;\\Delta$.$~~~~$We’ll prove version2 in this case.$~~~~$Let $\\overline L$ be an inv-label such that$~~~~v$ is the inv-root of $G$ w.r.t. $\\overline L$.$~~~~$We color $G$ in ordering $\\overline\\sigma$.$~~~~$By Lemma2 $\\vert P_{\\overline L}(w)\\vert\\leq\\Delta-1,\\text{ }\\forall\\text{ }w\\neq v$,$~~~~$So $\\Delta$ colors suffice $w$.$~~~~$Also $\\Delta$ colors suffice $v$, noting that $d(v)&lt;\\Delta$.Case IV: $\\Delta\\geq3$ and $G$ is regular but not biconnected;$~~~~$Since $G$ isn’t biconnected, $G$ contains a cut $v\\in V$.$~~~~$Let $G-v=H_1\\oplus H_2\\oplus\\cdots\\oplus H_s$ with $s\\geq2$.$~~~~$Let $G_i=G[V(H_1)\\cup\\lbrace v\\rbrace]$ for $i\\in[s]$.$~~~~$Noting that $d_{G_i}(v)&lt;\\Delta(G)=\\Delta(G_i)$ and $G_i$ is irregular,$~~~~$we have $\\chi(G_i)\\leq\\Delta(G_i)=\\Delta(G)$.$~~~~$$\\Delta(G)$ colors suffice $G$ if we color $v$ firstly and then every $G_i$.Case V: $\\Delta\\geq3$ and $G$ is regular and biconnected.$\\square$ ConceptInv-DFS Spanning TreeA graph is a tree providedit’s connected with no cycles.$T$ is a spanning tree of a connected graph $G$,provided $T$ is a tree,and $V(T)=V(G)$,and $E(T)\\subset E(G)$. Let $\\sigma=[v_1,v_2,\\cdots,v_n]$ be aDFS (depth first search) ordering of $G$.Define the label $L(v_i)=i$ for any $i\\in[n]$.Define the inv-label $\\overline L(v_i)=1+n-i$ for any $i\\in[n]$.The ordering $\\overline\\sigma=[v_n,v_{n-1},\\cdots,v_1]$is called an inv-DFS ordering of $G$. $T$ is a DFS spanning tree of $G$, provided$T$ is generated by a DFS of $G$, andthe direction of each edge is from the smaller labelto the larger label of its two vertices.The vertex with label $1$ is the root of $T$ w.r.t. $L$.$\\overline T$ is an inv-DFS spanning tree of $G$, provided$\\overline T$ is generated by a DFS of $G$, andthe direction of each edge is from the smaller inv-labelto the larger inv-label of its two vertices.The vertex with inv-label $n$ is the inv-root of $\\overline T$ w.r.t. $\\overline L$. Lemma1This lemma asserts that none inv-root vertexmust point to a neighbor vertex with larger inv-label.Lemma1 $\\forall\\text{ }v\\in V:\\text{ }\\overline{L}(v)\\neq n,\\text{ }\\exists\\text{ }w\\in N(v)\\text{ s.t. }\\overline{L}(v)&lt;\\overline{L}(w).$ PROOF:Suppose to the contrary$\\exists\\text{ }v\\in V:\\text{ }\\overline{L}(v)\\neq n,\\text{ s.t. }\\forall\\text{ }w\\in N(v):\\text{ }\\overline{L}(v)&gt;\\overline{L}(w)$,which means the inv-root and $v$ are unreachable in the DFS,violating that the graph is connected.$\\square$ Inv-label Predecessors and SuccessorsThe larger inv-label successors $S_{\\overline L}(v)$ of $v\\in V$is defined by $S_{\\overline L}(v)=\\lbrace w\\in N(v):\\overline{L}(v)&lt;\\overline{L}(w)\\rbrace$. The smaller inv-label predecessors $P_{\\overline L}(v)$ of $v\\in V$is defined by $P_{\\overline L}(v)=\\lbrace u\\in N(v):\\overline{L}(u)&lt;\\overline{L}(v)\\rbrace$. Lemma2This lemma gives the bound of $S_{\\overline L}$ and $P_{\\overline L}$.Lemma2 $\\forall\\text{ }v\\in V:\\text{ }\\overline{L}(v)\\neq n$$\\begin{cases}\\vert S_{\\overline L}(v)\\vert\\geq1 \\\\\\vert P_{\\overline L}(v)\\vert\\leq d(v)-1\\leq\\Delta-1\\end{cases}$ PROOF:Noting that $\\vert P_{\\overline L}(v)\\vert=d(v)-\\vert S_{\\overline L}(v)\\vert$,and by Lemma1 $S_{\\overline L}(v)\\neq\\emptyset$.$\\square$ DefinitionDefine the set $[k]=\\lbrace1,2,\\cdots,k\\rbrace$,for any positive integer $k\\in\\mathbb{Z}^+$.Define the set $\\binom{A}{k}=\\lbrace B\\subset A:\\vert B\\vert=k\\rbrace$for any proper $A$ and $k$. $X=X_1\\oplus X_2\\oplus\\cdots\\oplus X_s$ is a partition of set $X$,provided $X=\\bigcup\\limits_{i\\in[s]}X_i$,and $X_i\\cap X_j=\\emptyset$ for any distinct $i,j\\in[s]$. $G$ is a (simple) graph(finite, undirected, unweighted,with no self-cycles and multi-edges).$V=V(G)$ is the vertex set of $G$.$E=E(G)$ is the edge set of $G$.$n=\\vert V\\vert$ is the order of $G$.$m=\\vert E\\vert$ is the size of $G$. The incident edges $E_v$ of $v\\in V$,is defined by $E_v=\\lbrace e\\in E: v\\in V(e)\\rbrace$. Graph $H$ is a subgraph of Graph $G$,denoted by $H\\leq G$,provided $V(H)\\subset V(G)$ and $E(H)\\subset E(G)$. Set $U\\subset V(G)$.The induced subgraph of $G$ generated by $U$,denoted by $G[U]$,is defined by $V(G[U])=U$, and$E(G[U])=\\lbrace e\\in E(G):V(e)\\subset U\\rbrace$. The chromatic number of $G$,denoted by $\\chi(G)$, is the minimumnumber $k$ such that $G$ is $k$-colorable.$G$ is $k$-colorable, providedthere exists a coloring $c:V\\longrightarrow[k]$.A (proper/valid) ($k$-)coloring $c$ of $G$ isa function $c:V\\longrightarrow[k]$ such that$c(u)\\neq c(v)$ for any $(u,v)\\in E$. $N(v)$ is the (open) neighbors of vertex $v\\in V$,defined by $N(v)=\\lbrace u\\in V:(u,v)\\in E\\rbrace$.$N[v]=\\lbrace v\\rbrace\\cup N(v)$ is the closed neighbors. $d(v)$ is the degree of vertex $v\\in V$,defined by $d(v)=d_G(v)=\\vert N(v)\\vert$.$\\Delta(G)$ is the maximum degree of $G$,defined by $\\Delta=\\Delta(G)=\\max\\limits_{v\\in V}d(v)$.$\\delta(G)$ is the minimum degree of $G$,defined by $\\delta=\\delta(G)=\\min\\limits_{v\\in V}d(v)$. $G$ is regular provided$d(u)=d(v)$ for any $u,v\\in V$,otherwise $G$ is irregular. $G$ is a complete graph,provided $d(v)=n-1$ for any $v\\in V$.A complete graph with order $n$is denoted by $K_n$. $G$ is a cycle,provided $d(v)=2$ for any $v\\in V$,and $G$ is connected.If $n\\equiv1(\\mod2)$,then $G$ is an odd cycle,otherwise $G$ is an even cycle. $G$ is connected provided$u\\sim v$ for any distinct $u,v\\in V$,otherwise $G$ is disconnected.$u,v\\in V$ are reachable,denoted by $u\\sim v$, providedthere exists a $u,v$ path,otherwise unreachable and $u\\nsim v$.A $u,v$ path is a list $[w_1,w_2,\\cdots,w_{l+1}]$satisfying $w_1=u$ and $w_{l+1}=v$,and $w_i\\neq w_j$ for any distinct $i,j\\in[l+1]$,and $(w_i,w_{i+1})\\in E$ for any $i\\in[l]$.The $u,v$ path $[w_1,w_2,\\cdots,w_{l+1}]$,or simply $w_1w_2\\cdots w_{l+1}$,has length $l\\in\\mathbb{Z}^+$. The graph $G-v$ is obtained from $G$by deleting $E_v$ and $v$,for vertex $v\\in V$.The graph $G-U$ is defined by$G-U=G-u_1-u_2-\\cdots-u_s$,for any $U=\\lbrace u_1,u_2,\\cdots,u_s\\rbrace\\subset V$. $G$ is $k$-(vertex-)connected provided$G-U$ is connected for any $U\\subset V$ with $\\vert U\\vert=k-1$.$G$ is biconnected when $G$ is $2$-connected.A vertex $v\\in V$ is a cut of $G$ provided$G-v$ is disconnected. Graph $H$ is disconnected.$V(H)=V_1\\oplus V_2\\oplus\\cdots\\oplus V_s$ is a partition of $V(H)$.The induced subgraphs $H[V_1],H[V_2],\\cdots,H[V_s]$are the components of $H$, provided$H[V_i]$ is connected for any $i\\in[s]$,and $v_i\\in V_i,v_j\\in V_j$ are unreachable for any distinct $i,j\\in[s]$.We write $H=H_1\\oplus H_2\\oplus\\cdots\\oplus H_s$,if denoting $H_i=H[V_i]$ for any $i\\in[s]$,","link":"/2024/04/10/Brooks-Theorem/"},{"title":"Configure CentOS Environment on MacOS","text":"苹果电脑本地配置CentOS环境 近期在苹果电脑本地搞项目，需要干净的开发测试环境。尝试方案：MacOS安装Docker拉CentOS镜像。以下是具体步骤及可能出现的问题。 清理环境MacOS以前也装过Docker，先删除干净。其他不用的文件、软件删了腾出空间。 安装Docker 下载包选择是Intel Processor还是Apple Chip（左上角About This Mac） MacOS必须是最近3个版本（Mojave无法打开docker.dmg，升到最新的Sonoma，如果进度卡住重启再试一次，折腾2小时） 安装Linux Linux选择最经典的CentOS7（考虑到需要支持C++17，后续需要考虑迁移到CentOS8） 注册dockerhub（国内目前无法登录） 实测以上注册可以跳过，直接命令行下Docker拉取CentOS7镜像 启动一个CentOS7容器，进入命令行，创建用户，配置基本环境，持久化生成新的镜像（以后都使用这个镜像） 容器获取本地时区 启动项目 本地创建目录，用于git clone项目，与容器共享 新的镜像启动一个容器，挂载到本地目录，为防止这个容器爆掉限制启动内存4g 容器内配置项目环境，持久化再生成镜像（以后启动都使用这个镜像） Docker.CentOS7下root安装rpmbuild，构建RPMs必须从root切换到其他user 公共基础配置在root下进行，非公共配置、跑实例在非root下进行；若跑实例的数据都挂载到本地，也可直接root下运行 本地多个镜像构成了继承派生关系的有向图，中间镜像若命令行也无法强制删除可在DockerDesktop上删除 Docker.CentOS7.root更新g++版本 Docker.CentOS7.root更新cmake版本 cmake背景知识 Docker.CentOS7.root安装OpenSSL Docker.CentOS7.root安装git 升级git 报错curl Docker.CentOS7.root安装编译配置googletest 编译器相关$\\textbf{src-files}\\xrightarrow[\\text{check declaration/grammar errors}]{\\textbf{compile}}$$\\textbf{ obj-files}\\xrightarrow[]{\\textbf{pack}}\\textbf{library/archive-files}$$\\textbf{ }\\xrightarrow[\\text{check definition errors}]{\\textbf{link}}\\textbf{exe-files}$ makefile: Linux C/C++ 编译规则的脚本语言，每个项目的每个功能都有一个makefile配置文件，通过make命令执行，实现自动化编译CMakeLists.txt: 每个项目都有一个CMakeLists.txt文件，通过cmake ..命令生成所有makefile，不必再写makefile cmake官方基础教程 C++编译工具cmake vs bazel 编译问题汇总 undefined reference to pthread_create cmake ../ -DTEST=ON -Dgtest_disable_pthreads=OFF unknown type name z_size_t zlib版本从1.2.13回滚1.2.12 Linux常用命令 查找文件 12find . -name CMakeLists.txt #当前目录递归查找所有名为CMakeLists.txt的文件find . -type f |xargs grep &quot;edgeHash&quot; #当前目录递归查找包含&quot;edgeHash&quot;内容的文件 Vim生成空行Linux终端进入Vim命令模式下，执行 1command + O 在当前行下生成一个空行，并进入编辑模式 Vim光标快速跳转Linux终端进入Vim命令模式下，执行 1234gg # 跳转到文件开头G # 跳转到文件末尾0 # 跳转到行首$ # 跳转到行尾 永久设置alias 12vim ~/.bashrcalias cd...='cd ../..' # 返回上上层目录","link":"/2024/03/09/Configure-CentOS-Environment-on-MacOS/"},{"title":"DeepFM 实战","text":"Github 下载轮子注意事项 从 Tensorflow2.0 切换到 1.14.0 Python 切换到 3.6.8 手动下载添加 yellowfin 包 下载 Kaggle 数据","link":"/2021/08/30/DeepFM-%E5%AE%9E%E6%88%98/"},{"title":"FM 模型训练问题汇总","text":"problem 0DataFrame 转置再转字典 12dv = DictVectorizer()X_train_vec = dv.fit_transform(list(X_train.T.to_dict().values)) 出现告警 1Warning: DataFrame columns are not unique, some columns will be omitted python solution转置之前的行索引index有duplicate 12345678910111213141516X_train = df_train[fm_feature_cols]y_train = df_train[LABEL_COL].valuesy_train_cls = (y_train&gt;=PARAM_LABEL_THRES).astype(np.int32)X_test = df_test[fm_feature_cols]y_test = df_test[LABEL_COL].valuesy_test_cls = (y_test&gt;=PARAM_LABEL_THRES).astype(np.int32)print('is X_train.index unique? {0}'.format(X_train.index.is_unique))print('is X_test.index unique? {0}'.format(X_test.index.is_unique))X_train.reset_index(drop=True, inplace=True)X_test.reset_index(drop=True, inplace=True)dv = DictVectorizer()X_train_vec = dv.fit_transform(list(X_train.T.to_dict().values))X_test_vec = dv.transform(list(X_test.T.to_dict().values))fm = pylibfm.FM(num_factors=10, num_iter=iters, verbose=True, task='classification', init_learning_rate=0.001, learning_rate_schedule='optimal')fm.fit(X_train, y_train_cls)preds = fm.predict(X_test_vec) problem 112345678910X_train = df_train[fm_feature_cols]y_train = df_train[LABEL_COL].valuesy_train_cls = (y_train&gt;=PARAM_LABEL_THRES).astype(np.int32)X_test = df_test[fm_feature_cols]y_test = df_test[LABEL_COL].valuesy_test_cls = (y_test&gt;=PARAM_LABEL_THRES).astype(np.int32)dv = DictVectorizer()X_train_vec = dv.fit_transform(list(X_train.T.to_dict().values))X_test_vec = dv.transform(list(X_test_vec.T.to_dict().values))fm.fit(X_train_arr, y_train_cls) 报错 1ValueError: Found input variables with inconsistent numbers of samples 原因 12345print('len(X_train_arr)={0}'.format(X_train_arr.shape[0]))print('len(y_train_cls)={0}'.format(len(y_train_cls)))#len(X_train_arr)=245299#len(y_train_cls)=503458#X_train 和 y_train_cls 长度不一致 solution123dv = DictVectorizer()X_train_vec = dv.fit_transform(list(X_train.T.to_dict().values()))X_test_vec = dv.transform(list(X_test.T.to_dict().values())) problem 21TypeError: sparse matrix length is ambiguous; use getnnz() or shape[0] solution12print('len(X_train)={0}'.format(len(X_train)))print('len(y_train_cls={0}'.format(len(y_train_cls))) 这里没问题 1234567dv = DictVectorizer()X_train_vec = dv.fit_transform(list(X_train.T.to_dict().values()))X_test_vec = dv.transform(list(X_test.T.to_dict().values()))print('len(X_train_vec)={0}'.format(len(X_train_vec)))print('len(y_train_cls)={0}'.format(len(y_train_cls)))print('len(X_test_vec)={0}'.format(len(X_test_vec)))print('len(y_test_cls)={0}'.format(len(y_test_cls))) 这里报错，改为 1234567dv = DictVectorizer()X_train_vec = dv.fit_transform(list(X_train.T.to_dict().values()))X_test_vec = dv.transform(list(X_test.T.to_dict().values()))print('len(X_train_vec)={0}'.format(X_train_vec.shape[0]))print('len(y_train_cls)={0}'.format(len(y_train_cls)))print('len(X_test_vec)={0}'.format(X_test_vec.shape[0]))print('len(y_test_cls)={0}'.format(len(y_test_cls))) problem 3使用 DictVectorizer 向量化 DataFrame由于 DataFrame 数据量超过 1G自动转为 scipy.sparse.sparse.csr.csr_matrix 类型不能直接用于 pylibfm.FM.fit先将 csr_matrix 转为 list 再训练内存超过此 Python 进程内存达到 270 G 直接爆掉触发 OOM 从而 linux 内核 kill 该进程 problem 4训练 pylibfm.FM 模型 12-- Epoch 161Training log loss: nan solution可能列的数据类型问题 =&gt; 检查发现问题(object类型需要转成string类型，但不影响训练结果)目前 github 项目 pyFMclassification存在bug两次调用sigmoid函数01 classification log loss 改为 regression mse problem 501分类应用regression模型 12fm = pylibfm.FM(num_factors=10, num_iters=iters, verbose=True, task='regression', init_learning_rate=0.001, learning_rate_schedule='optimal')fm.fit(X_train_arr, y_train_cls) 报错 1ValueError: Buffer dtype mismatch, expected 'DOUBLE' but got 'int' solution1y_train_cls = (y_train.values&gt;=PARAM_LABEL_THRES).astype(np.float64) problem 6分类改为回归 12fm = pylibfm.FM(num_factors=10, num_iters=iters, verbose=True, task='regression', init_learning_rate=0.001, learning_rate_schedule='optimal')fm.fit(X_train_arr, y_train_cls) 仍然出现问题 12-- Epoch 1Training MSE: nan solution少数据量/多数据量分别测一下=&gt; 少量数据 classification 正常 problem 7少数据量测试报错 123-- Epoch 1Training MSE: nanValueError: Input contains NaN, infinity or a value too large for dtype('float64') 回归 label 训练溢出（可能原因是某些特征未归一化） solution=&gt;直接改为分类-&gt;NaN=&gt;改为分类并且特征归一化-&gt;结果正常(1000样本) 结果正常(10000样本) 临界点60万样本120特征 内存不足(全部样本) problem 8模型验证 12preds = fm.predict(X_test_csr)test_logloss = log_loss(y_test_cls, preds) 报错 12ValueError: y_true contains only one label (0).Please provide the true labels explicitly through the labels argument. solution验证集的label全为0没有1随机划分训练集验证集=&gt;分层划分 12345678910111213141516def split_train_valid_random(df, test_frac=0.1): df = df.sample(frac=1).reset_index(drop=True, inplace=True) n_test = int(len(df) * test_frac) df_test, df_train = df[:n_test], df[n_test:] df_train.reset_index(drop=True, inplace=True) df_test.reset_index(drop=True, inplace=True) return df_train, df_testdef split_train_valid_stratify(df, primary_key='chatroom_id', label='clickuv', test_frac=0.1): df = df.drop_dumplicates(subset=[primary_key, label]) x = df[primary_key].values y = df[label].values y = (y / 3).astype(int) y[np.where(y &gt; 5)] = 5 row_train, row_test, _, _, = train_test_split(x, y, stratify=y, test_size=test_frac) return row_train, row_test","link":"/2021/08/13/FM-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/"},{"title":"FM 系列模型性能比较","text":"基本 FM 模型包 libfm | C++11 pywfm | python alphaFM | C++11 fastFm | C/Cython/Python pyFM | Python libFM | Tensorflow spark-libFM | scala DiFacto | C++ pyFM 测试 实验序号 raw features linear features factors iters 训练时间 总时间 训练集 row 训练集 logloss 验证集 row 验证集 logloss 验证集 auc 验证集 acc 测试集 row 测试集 logloss 测试集 auc 测试集 acc 机器 1 124 40w 10 20 1h38m 2h36m 518648 0.33822 162770 0.3947 0.8268 0.8303 31979 1.1479 0.6123 0.2320 luban 服务器 2 124 40w 15 30 4h4m 4h52m 518742 0.30285 162548 0.3635 0.8564 0.8503 31979 1.1922 0.5778 0.2511 luban 服务器 3 4 2w 15 30 1h49m 2h41m 4000000 0.31214 1000000 0.3669 0.8342 0.8480 31979 1.8640 0.4074 0.1390 luban 服务器 4 4 2w 4 60 2h57m 3h15m 5000000 0.30302 1250000 0.3673 0.8333 0.8477 31979 1.9496 0.5598 0.1653 luban 服务器 5 4 2w 8 60 3h16m 4h15m 5000000 0.28222 1250000 0.3492 0.8489 0.8575 31979 1.9372 0.5023 0.1454 luban 服务器 6 4 2w 30 30 4h19m 5h18m 5000000 0.28640 1250000 0.3478 0.8461 0.8585 31979 1.8359 0.4332 0.1513 luban 服务器 7 22 8w 30 30 6h18m 7h9m 2000000 0.29670 500000 0.3769 0.8208 0.8457 31979 2.3700 0.6774 0.0919 luban 服务器 8 22 8w 20 30 4h20m 5h10m 2000000 0.30264 500000 0.3809 0.8165 0.8437 31979 2.2959 0.4705 0.1144 luban 服务器 9 22 8w 20 30 4h31m 5h28m 2000000 0.28568 500000 0.3750 0.8208 0.8474 31979 2.1205 0.2859 0.1672 luban 云平台 10 22 8w 40 40 22h28m 23h33m 4000000 0.20939 1000000 0.2838 0.9051 0.8923 31979 4.3235 0.7143 0.1193 luban 云平台 11 22 8w 40 40 43h58m 46h43m 7846452 0.26457 2000000 0.3044 0.8927 0.8766 1453918 0.4240 0.7056 0.8524 luban 云平台 train_all (features=124) 效果不佳train_naked (features=4) 近似随机噪声train_basic (features=22) ‘硬train一发‘测试集AUC提升至0.7","link":"/2021/08/23/FM-%E7%B3%BB%E5%88%97%E6%A8%A1%E5%9E%8B%E6%80%A7%E8%83%BD%E6%AF%94%E8%BE%83/"},{"title":"Graph Minor","text":"Edge Deletion$G=(V,E)$ is a graph.$\\mathcal{G}$ is the set of all graphs with any vertices and any edges.$\\mathcal{G}_{i,j}$ is the set of all graphs with $i$ vertices and $j$ edges.For $e\\in E$,$D_e:\\mathcal{G}\\longrightarrow\\mathcal{G}$ is an edge-deletion operationsatisfying for $G=(V,E)\\in\\mathcal{G}\\text{ and }G’=(V’,E’)=D_e(G)$ it holds that$V’=V$ and $E’=E\\setminus\\lbrace e\\rbrace$. The graph $D_e(G)$ is also denoted as $G-e$ or $G\\setminus e$. $\\underline{\\textbf{Lemma0}}$$G\\in\\mathcal{G}_{i,j}\\Longrightarrow D_e(G)\\in\\mathcal{G}_{i,j-1}$. Vertex DeletionFor $G=(V,E)$ and $v\\in V$,let $E_v=\\lbrace e\\in E:\\text{ }V(e)\\cap\\lbrace v\\rbrace\\neq\\emptyset\\rbrace$ bethe set of edges incident to $v$.$D_v:\\mathcal{G}\\longrightarrow\\mathcal{G}$ is an vertex-deletion operationsatisfying for $G=(V,E)\\in\\mathcal{G}\\text{ and }G’=(V’,E’)=D_v(G)$ it holds that$V’=V\\setminus\\lbrace v\\rbrace$ and $E’=E\\setminus E_v$. The graph $D_v(G)$ is also denoted as $G-v$ or $G\\setminus v$. $\\underline{\\textbf{Lemma1}}$$G\\in\\mathcal{G}_{i,j}\\Longrightarrow D_v(G)\\in\\mathcal{G}_{i-1,j-k}$where $k=\\vert E_v\\vert$. Edge ContractionFor $G=(V,E)$, and $w\\notin V$, and $e=(u,v)\\in E$,let $W=V\\cup\\lbrace w\\rbrace\\setminus\\lbrace u,v\\rbrace$ be the set of vertices merging $u,v$,and $E_w=\\lbrace(w,x):\\text{ }(u,x)\\in E\\text{ or }(v,x)\\in E\\rbrace$$=\\lbrace(w,x):\\text{ }(u,x)\\in E_u\\text{ or }(v,x)\\in E_v\\rbrace$,and $E’=E\\setminus E_u\\setminus E_v\\cup E_w$.$C_e:\\mathcal{G}\\longrightarrow\\mathcal{G}$ is an edge-contraction operationsatisfying for $G=(V,E)\\in\\mathcal{G}$ it holds that $C_e(G)=(V’,E’)$. The graph $C_e(G)$ is also denoted as $G/e$. $\\underline{\\textbf{Lemma2}}$$G\\in\\mathcal{G}_{i,j}\\Longrightarrow C_e(G)\\in\\mathcal{G}_{i-1,j-k}$where $k=\\vert E_v\\cap E_u\\vert$ for $e=(u,v)\\in E$. MinorNow that we have $3$ type ofoperations(Edge-Deletion/Vertex-Deletion/Edge-Contraction),for graphs $G$ and $H$,$H$ is said to be a minor of $G$,denoted as $H\\leq G$,if there exists a list of operations $O_1,O_2,\\cdots O_k$such that $H=O_k\\circ\\cdots\\circ O_2\\circ O_1(G)=O_k(\\cdots(O_2(O_1(G))))$. $\\underline{\\textbf{Lemma3(transitive)}}$$F\\leq H\\text{ and }H\\leq G\\Longrightarrow F\\leq G$. Vertex MergeFor $G=(V,E)$, and $U\\subset V$, and $u\\notin V$,define $E_U=\\lbrace(x,y)\\in E: \\lbrace x,y\\rbrace\\cap U\\neq\\emptyset\\rbrace$,and $E_{U_1}=\\lbrace(x,y)\\in E: \\vert\\lbrace x,y\\rbrace\\cap U\\vert=1\\rbrace$,and $E_u=\\lbrace(u,y): (x,y)\\in E_{U_1}\\text{ and }x\\in U\\rbrace$.Then $M_U:\\mathcal{G}\\longrightarrow\\mathcal{G}$ is a vertex-mergeoperation of $G$ satisfying for $M_U(G)=G’=(V’,E’)$it holds that $V’=V\\cup\\lbrace u\\rbrace\\setminus U$ and$E’=E\\cup E_u\\setminus E_U$. The graph $M_U(G)$ is also denoted as $G/U$. $\\underline{\\textbf{Theorem4}}$$G=(V,E)$ is a graph.$V_0,V_1,\\cdots,V_k$ is a partition of $V$.$G[V_i]$ is connected for each $i\\in\\lbrace1,2,\\cdots,k\\rbrace$.Let graph $H=(G-V_0)/V_1/\\cdots/V_k$.Let graph $F$ be any spanning subgraph of $H$.Then $F$ is a minor of $G$. PROOF:Since $F$ is a spanning subgraph of $H$,there exists s set of edge-deletion operations $D_{e_1},D_{e_2},\\cdots,D_{e_x}$such that $F=D_{e_x}\\circ\\cdots\\circ D_{e_2}\\circ D_{e_1}(H)$,meaning that $F$ is a minor of $H$.By transitive of minor, it suffices to show $H$ is a minor of $G$,which is true because $H=(G-V_0)/V_1/\\cdots/V_k$.$\\square$","link":"/2024/03/16/Graph-Minor/"},{"title":"Kruskal 习题集合","text":"Easy 入门暂无 Medium 普及 LeetCode 1631 Path With Minimum Effort 最小体力消耗路径题解 哔哩哔哩 西瓜视频推荐度 ☆☆☆ LeetCode 1584 Min Cost to Connect All Points 连接所有点的最小代价题解 哔哩哔哩 西瓜视频推荐度 ☆☆☆☆ Hard 提高暂无","link":"/2021/02/01/Kruskal-%E4%B9%A0%E9%A2%98%E9%9B%86%E5%90%88/"},{"title":"Manim 中文教程","text":"中文速成包含 背景图片","link":"/2021/08/16/Manim-%E4%B8%AD%E6%96%87%E6%95%99%E7%A8%8B/"},{"title":"ParseException line x:y cannnot recognize input near","text":"problemlinux 命令行执行 hive sql 脚本 run.sh 1234567#!/bin/shsource /etc/profilesource ~/.bash_profileyest=$(date -d &quot;-1 days&quot; &quot;+%Y-%m-%d&quot;)yest2=$(date -d &quot;-2 days&quot; &quot;+%Y-%m-%d&quot;)hive -hiveconf YEST_DATE${yest} YEST2_DATE=${yest2} -f test.sql &gt; test.csv 报错 1FAILED: ParseException line xx:yy cannot recognize input near '$' '{' 'hivevar' in select clause 1FAILED: ParseException line xx:yy cannot recognize input near 'where' 'city_id' '=' in subquery source solution脚本 test.sql 存在语法不严谨","link":"/2021/08/23/ParseException-line-x-y-cannnot-recognize-input-near/"},{"title":"Permutation Importance","text":"Scikit-learn の Random Forest の Permutation importance を計算Sckit-learn的Random Forest的featureimportance_ 是Gini importance，可能有偏差。如果在意偏差的话，可以使用rfpimp等模块来计算并评价Permutation importance。 背景Random Forest对不需要计算成本却能显示出良好的预测性能非常满意，不过也有非线性的，说明变量的重量没有正负，评价也有困难的时候。 我觉得没有什么好的方法，查了很多之后，因为是千回百转的学习，所以作为备忘录整理好。 结果找到了以下的Repository。parrt/random-forest-importances 嗯，好像计算Permutation importance的重量的module。想着Permutation importance是什么呢，正好用日语整理的Tweet被Retweet了。Twitter好厉害。 用构建了OOB和外部套装等预测模型构筑中未使用的数据的预测模型进行预测，以当时的预测性能为基础线。然后，将某个说明变量的值像y-randomization那样打乱，构建预测模型，同样计算预测性能。那个时候，那个说明变量越重要预测性能就越大。通过各说明变量将其作为重要度的是Permutation Importance。 嗯，Random Forest的重要性例如像以下幻灯片的第8张那样“在制作决定木后随机地更换说明变量。之后预测OOB，根据更换前和预测性能的差来计算”，所以“感觉差不多，差别也会有那么大的变化吗？”一开始是这么想的。 但是，从最初介绍的rfpimp首页的链接可以进行的这个Repository作者的博客里有以下文章。https://explained.ai/rf-importance/index.html 123The most common mechanism to compute feature importances, and the one used in scikit-learn’s RandomForestClassifier and RandomForestRegressor, is the mean decrease in impurity (or gini importance) mechanism (check out the Stack Overflow conversation). 在Scikit-learn中，各说明变量的重要性是用Gini importance这个指标来计算的。 Gini importance简单来说就是Gini系数越小越容易判别的值，由于各说明变量的关系，需要变小多少的指标。如果是日语的话，以下的网站比较容易理解。 因为是难得的机会，所以在Sckit-learn的module中也试着看了一下。RandomForestClassifier在其中使用DecisionTreeClassifier。而且DecisionTreeClassifier好像使用了其中cython写的代码。所以才高速的吧。我虽然不能读cython，但是我发现了可能是这里的部分。 可以看出是取了差别作为importance。另外，DecisionTreeClassifier的Docomentation上也写着使用Gini importance。 也就是说，Sckit-learn的Random Forest的说明变量的重量是“在制作决定树后随机更换说明变量。之后预测OOB，根据更换前和预测性能的差来计算”，这是我的误解，实际上是使用Gini importance的。 因此，Repository的作者制作了寻求Permutation importance的module。终于理解了。学到了很多。 关于rfpimp module学习了很多东西，这次请允许我省略。不仅可以简单地计算Permutation importance，还可以汇总多个说明变量来计算Permutation importance，我觉得这是非常有趣的module。刚才介绍的作者的博客上也写了偏颇情况的说明，Jupter Notebook上也有易懂的Example，真是帮了我大忙了。 最后Gini importance当然也有好的地方，那就是重量计算快的地方之一。因为Permutation importance在其性质上需要多次进行预测模型构筑，所以比起Gini importance，计算权重更花费时间，可以说很容易地反复进行。 另一方面，Permutation importance不仅适用于Random Forest，也适用于其他机器学习方法，特别是对SVM等以往说明变量的权重无法得到的方法，由此可求出说明变量的权重。请一定要熟练使用。","link":"/2021/09/02/Permutation-Importance/"},{"title":"SPARK SQL ...including 1 partition column(s) having constant value(s)","text":"Solution 1select * from partitioned_table导致不能被选择的常数分区列将脚本中所有的 select * 展开为每一列REF 2彻底删除整个表drop table if exists table_dev; √alter table table_dev if exists partition (dt=’year-month-day’); × 3通过改变create table if not exists table_dev (col1 string, col2 string) partitioned by (dt string);中的列的数量发现问题2 4调试的方法一个是单元测试，一个是AB测试","link":"/2021/07/30/SPARK-SQL-including-1-partition-column-s-having-constant-value-s/"},{"title":"Revival","text":"回归 Github 博客2021 伊始，疫情已延烧一年之久，开源节流刻不容缓，遂由阿里云服务器 + 域名 + WordPress 回归 Github 免费个人主页。 Git+Hexo 搭建博客搭建教程可 Google 之，这里仅对注意事项作一个 remark。 blog 配置文件 __config.yml 添加自定义主题 theme: icarus 前面不要有空格，否则无法识别 注意执行各种命令的路径不能弄乱套，实在不行就删除 blog 文件夹重新 npm 下载 hexo-cli github 的 repository 添加 README.md 在 hexo d 之后被删除，Hexo 如何配置 icarus 主题自定义头像路径 css/images/avatar.png，icarus 网站图标路径 img/logo.png，可在 github 的 repository 中看到 分享链接需要注册 addthis 自定义样式，获取 install_url，修改 sharethis 为 addthis，url 必须加单引号 donate 的 qrcode 可用支付宝和微信收款码，与 logo 放在一起，路径不需加单引号 disqus 邮箱注册之后必须 get started 才能看到 Website Name (shortname)，直接登录账号进行 setting 是不行的，接下来 select platform 时选择最后的手动安装直接 configure","link":"/2021/01/28/Revival/"},{"title":"Swing&#x2F;user-cf&#x2F;item-cf召回算法","text":"introductionSwing 意为荡秋千，表示 item-user-item 三角关系，该算法是阿里提出的召回算法，对物品 i,j 的所有共同购买用户 U，计算从任意两个用户 u,v 的角度得到 i,j 的相似度$s(u,v,i,j)=\\frac{1}{\\alpha + \\left|I_u\\cap I_v\\right|}$然后求和得到 i,j 的相似度$\\textbf{sim}(i,j) = \\sum_{u\\in U}\\sum_{v\\in U} s(u,v,i,j)$ user-cf 基于相似用户之间的物品扩散item-cf 基于相似物品之间的用户扩散二者做复合运算，与分开两路召回相比，复杂度多一层循环，对用户推荐的物品增多可考虑基于四部图随机游走的 tradeoff 方案 question该算法的假设是若两用户 u,v 除 i,j 外的共同购买物品越多，则 i,j 相似度越低若两用户 u,v 除 i,j 外的共同购买物品越少，则 i,j 相似度越高这个假设难以理解，我的观点如下：若两用户 u,v 除 i,j 外的共同购买物品越多，则 u,v 相似度越高若两用户 u,v 除 i,j 外的共同购买物品越少，则 u,v 相似度越低这表示 i,j 具有强转移性，所以 Swing 算法召回的是具有强转移性(互补/关联)的物品，而不是具有相似性的物品","link":"/2021/08/09/Swing-%E5%8F%AC%E5%9B%9E%E7%AE%97%E6%B3%95/"},{"title":"Tao","text":"0选择一两个可谋生或有兴趣的赛道 纵向有节奏提升 横向对齐高端玩法 1系统思维框架 总体完整 细节可执行可展示 2结果导向 模块化拆解组装 路径可回溯复盘","link":"/2021/08/21/Tao/"},{"title":"Union Find Set 习题集合","text":"Easy 入门暂无 Medium 普及 洛谷 P3367 【模板】并查集题解 哔哩哔哩 西瓜视频推荐度 ☆☆☆☆☆ Hard 提高暂无","link":"/2021/02/02/Union-Find-Set-%E4%B9%A0%E9%A2%98%E9%9B%86%E5%90%88/"},{"title":"fastFM 安装","text":"Github 多次下载 zipfastFM-core 包含两个外部项目","link":"/2021/08/31/fastFM-%E5%AE%89%E8%A3%85/"},{"title":"fatal unable to access github","text":"problem 1部署 hexo 1hexo d 报错 1fatal: unable to access 'https://github.com/edogawashinichi/edogawashinichi.github.io.git/': The requested URL returned error: 403 solution2021-08-13 起 github 不再允许自动保存密码Personal Access Token kartik tyagi problem 2部署 hexo 1hexo d 报错 1fatal: unable to access 'https://github.com/edogawashinichi/edogawashinichi.github.io.git/': Failed to connect to github.com port 443: Operation timed out 或 1fatal: unable to access 'https://github.com/edogawashinichi/edogawashinichi.github.io.git/': LibreSSL SSL_connect: SSL_ERROR_SYSCALL in connection to github.com:443 solution网络问题，重复执行几次 hexo d","link":"/2021/08/16/fatal-unable-to-access-https-github-com-edogawashinichi-edogawashinichi-github-io-git/"},{"title":"hexo back","text":"知乎太坑，转回github。 环境调通好久不用，环境有些问题，解决https://blog.csdn.net/eagleuniversityeye/article/details/85267550在package.json目录下执行npm install hexo-server –save 命令忘差不多了，攒起来同样在package.json目录下启动本地服务 hexo s写文章 hexo new “文章标题”清空public下的内容 hexo clean把source的内容生成到public下 hexo g把public下的内容同步到github仓库 hexo d github需要使用PAT代替密码进行远程连接解决https://stackoverflow.com/questions/68775869/message-support-for-password-authentication-was-removed 用的免费梯子，hexo d经常连不上githubfatal: unable to access ‘https://github.com/需要多试几次（一般需要3次）hexo d成功github.io页面刷新一般也存在一定延时 hexo d同步自动使用github原来的账号密码解决：把https方式改为http方式https://www.lintstar.top/2021/08/4b8ee7df.html#Hexo-连接-Github host key verification failed原因是github.com更换了ip解决：重新连接保存到本地https://timmousk.com/blog/host-key-verification-failed-git/ git@github.com: Permission denied (publickey)原因：github新版本删除了原来的mac笔记本的ssh-pubkey解决：github增加两个ssh-pubkey（authentication,signing)https://docs.github.com/en/authentication/connecting-to-github-with-ssh/adding-a-new-ssh-key-to-your-github-account github加载不出settings页面解决：直接输入https://github.com/settings回车 发博客流程命令行都在package.yml所在路径下执行 本地创建文章1hexo new &quot;文章标题&quot; 编辑文章使用sublime或vim 重新渲染生成网页12hexo cleanhexo g 本地预览1hexo s 浏览器登录localhost:4000 同步到远程1hexo d","link":"/2024/02/29/hexo-back/"},{"title":"install pyFM","text":"手动安装国内 github 不稳定，先下载再安装 在https://github.com/coreylynch/pyFM中手动下载包 将包解压，更改里面的setup.py文件，去掉setup.py文件里面的libraries=[“m”]一行 cd到当前文件夹下python setup.py install 参考","link":"/2021/08/12/install-pyFM/"},{"title":"macOS Linux 文件解压缩","text":"Linux 文件解压12sudo yum install p7zip7za x file.7z macOS 文件压缩17z a dest.7z src_folder macOS 文件解压127z x file.7z7z x file.rar","link":"/2021/08/30/macOS-Linux-%E6%96%87%E4%BB%B6%E8%A7%A3%E5%8E%8B%E7%BC%A9/"},{"title":"model saving disabled","text":"problem在 jupyter notebook 上打开保存的模型文件报错 123Error! ./models/fm_scaler.mdl is not UTF-8 encodedSaving disabled.See Console for more details. solution误导性输出因为 jupyter 无法打开二进制文件服务器终端查看文件类型 12file fm_scaler.mdlfm_scaler.mdl 8086 relocatable (Microsoft)","link":"/2021/08/20/model-saving-disabled/"},{"title":"no module named tkinter","text":"problem执行 Python 脚本 1import matplotlib.pyplot as plt 报错 1ModuleNotFoundError: No module named '_tkinter' solution需要重新安装Python","link":"/2021/08/16/no-module-named-tkinter/"},{"title":"pyFM vs fastFM","text":"Translation 使用 Movielens 尝试分解机 Python 实现 pyFM、fastFM——2019 年 12 月 11 日你好，我是 Guglilac (@guglilac)。 本文是关于对 Movielens 数据集使用 pyFM 和 fastFM 这两个最大的因子分解机 (FM) 的 Python 实现。 如何使用fastFMGitHub - ibayer/fastFM: fastFM: A Library for Factorization Machines 据说不仅可以使用回归和分类，还可以使用 BPR 损失来预测排名，但是在另一个人的文章中，BPR 不起作用。 我也和这篇文章分开试过BPR loss，但是没学好。在本文中，Movielens 用于评分预测，所以让我们仅使用回归模型来学习。 输入以与 pyFM 相同的方式作为 scipy 的稀疏矩阵给出。结果只贴pyFM，这里只贴写法。 只需初始化并正常安装即可。 123from fastFM import als,sgdmodel = als.FMRegression(n_iter=100, l2_reg_w=0.1, l2_reg_V=0.1, rank=10)model.fit(X_train,y_train) 但是，默认情况下，根本不显示学习历史，也不应用学习曲线，因此不清楚学习是否在进行。 如果你查一下，指南 — fastFM 0.2.10 文档 正如本页所写，似乎您需要自己实现显示学习历史的部分。 当我试图模仿它时， 12345678910111213141516171819202122from sklearn.metrics import mean_squared_errorimport numpy as npdef get_rmse(model,X, y): y_pred=model.predict(X) return np.sqrt(mean_squared_error(y_pred, y))def train(model,X_train,y_train,n_iter,iter_size=1): model.fit(X_train,y_train) # initのためにこれが必要 rmse_hist=[] iter_size=1 for i in range(n_iter): model.fit(X_train, y_train,n_more_iter=iter_size) rmse_train=get_rmse(model,X_train,y_train) rmse_hist.append(rmse_train) if (i+1)%10==0: print(f&quot; epoch = {i+1}, Train RMSE : {rmse_train: 0.4f}&quot;) return model,rmse_histmodel = als.FMRegression(n_iter=0, l2_reg_w=0.1, l2_reg_V=0.1, rank=10)model,history=train(model,X_train,y_train, n_iter=100) 需要实现模型初始化时n_iter = 0，迭代一次n_more_iter，更新模型，每次计算loss。 这次不包括验证，但当然您也可以包含验证数据来计算损失。 现在您可以根据历史绘制学习曲线。 如何使用 pyFMGitHub - coreylynch/pyFM: Factorization machines in python 这次使用的图书馆。仅支持回归和分类。 同样，输入作为稀疏矩阵给出。我为获取 Movielens 数据并对其进行处理的部分创建了自己的类。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960import numpy as npimport pandas as pdfrom scipy.sparse import csr_matrixfrom pathlib import Pathimport codecsimport category_encoders as ceclass MovielensLoader: def __init__(self, data_dir=Path(&quot;./ml-100k&quot;), user_filename=&quot;u.user&quot;,item_filename=&quot;u.item&quot;): self.data_dir = data_dir self.user_path = data_dir / user_filename self.item_path = data_dir / item_filename def create_dataset(self, include_user_features=True, include_item_features=True): df_train, y_train = self.load_log_and_ratings(log_filename=&quot;ua.base&quot;) df_test, y_test = self.load_log_and_ratings(log_filename=&quot;ua.test&quot;) target_col = [&quot;uid&quot;, &quot;mid&quot;] if include_user_features: users = self.load_users() target_col = list(set(target_col + users.columns.tolist())) df_train = pd.merge(df_train, users, on=&quot;uid&quot;) df_test = pd.merge(df_test, users, on=&quot;uid&quot;) if include_item_features: items = self.load_items() df_train = pd.merge(df_train, items, on=&quot;mid&quot;) df_test = pd.merge(df_test, items, on=&quot;mid&quot;) self.encoder = ce.OneHotEncoder(cols=target_col) X_train = self.encoder.fit_transform(df_train) X_test = self.encoder.transform(df_test) X_train = csr_matrix(X_train, dtype=np.float) X_test = csr_matrix(X_test, dtype=np.float) return X_train, y_train, X_test, y_test def load_log_and_ratings(self, log_filename, drop_columns=[&quot;timestamp&quot;]): logs = pd.read_csv(self.data_dir / log_filename, names=[&quot;uid&quot;, &quot;mid&quot;, &quot;rating&quot;, &quot;timestamp&quot;], sep=&quot;\\t&quot;, dtype=str) ratings = np.array(logs[&quot;rating&quot;], dtype=np.float) drop_columns.append(&quot;rating&quot;) logs = logs.drop(drop_columns, axis=1) return logs, ratings def load_users(self, drop_columns=[&quot;age&quot;, &quot;zip_code&quot;]): users = pd.read_csv(self.user_path, names=[&quot;uid&quot;, &quot;age&quot;, &quot;gender&quot;, &quot;occupation&quot;, &quot;zip_code&quot;], sep=&quot;|&quot;, dtype=str) users = users.drop(drop_columns, axis=1) return users def load_items(self): with codecs.open(self.item_path, &quot;r&quot;, &quot;Shift-JIS&quot;, &quot;ignore&quot;) as f: items = pd.read_table(f, names=[&quot;mid&quot;, &quot;title&quot;, &quot;released&quot;, &quot;video_released&quot;, &quot;IMDb_URL&quot;, &quot;unknown&quot;, &quot;Action&quot;, &quot;Adventure&quot;, &quot;Animation&quot;, &quot;Children&quot;, &quot;Comedy&quot;, &quot;Crime&quot;, &quot;Documentary&quot;, &quot;Drama&quot;, &quot;Fantasy&quot;, &quot;Film_Noir&quot;, &quot;Horror&quot;, &quot;Musical&quot;, &quot;Mystery&quot;, &quot;Romance&quot;, &quot;Sci_Fi&quot;, &quot;Thriller&quot;, &quot;War&quot;, &quot;Western&quot;], delimiter=&quot;|&quot;, dtype=str) items = items.drop([&quot;title&quot;, &quot;released&quot;, &quot;video_released&quot;, &quot;IMDb_URL&quot;], axis=1) return items 从 MovieLens | GroupLens 下载 Movielens 数据并只准备目录 ./ml-100k。由于 Movielens 在满负荷使用时数据过多，因此发布了各种大小的数据。这次我尝试使用 100k 数据。 Movielens 包含用户附加到项目（电影）的评分数据，每个用户和项目都与一个特征相关联。 用户特征包括年龄、性别、职业，项目特征包括流派。 这一次，我们将使用性别和职业作为用户特征，并使用类型作为项目。 FM 的优点是可以放入这些上下文信息。如果不使用，它将是一个类似于矩阵分解的模型。 这一次，有和没有这些上下文信息 1include_user_features=True, include_item_features=True 我试图通过部分参数来控制。 下面我们进行初始化和学习。 1pylibfm.FM(num_factors=10, num_iter=100, verbose=True, task=&quot;regression&quot;, initial_learning_rate=0.001, learning_rate_schedule=&quot;optimal&quot;) 让我们看看结果。下面，计算测试数据中的RMSE。 12345baseline 1.1220FM 1.1979 (user, itemあり)FM 1.1871 (itemだけ)FM 0.9417 (userだけ)FM 0.9465 (userもitemもなし) 基线是一个不断返回训练数据平均评分的模型。目前，在没有用户和项目的上下文（MF）和用户的附加信息的情况下，RMSE 低于基线，但结果是当包含项目的类型信息时，RMSE 增加。 我还没有调整超参数，所以也许这就是原因。 奖金（其他图书馆）GitHub - jfloff/pywFM: pywFM is a Python wrapper for Steffen Rendle’s factorization machines library libFM FM 作者 Rendle 的官方库 libFM 的 Python 包装器。仅支持回归和分类。 pyfms · PyPI 它是基于 theano 的，但我也发现了类似的东西。很抱歉我没有正确地看到它。 综上所述我尝试使用一次热编码使用 pandas 的 get_dummies 一次，但是如果在测试时出现 train 时不存在的特征，或者相反，如果 train 时存在的某些东西在测试时消失，维度是我不能用的，因为我做不到。 查了一下，Category Encoders 转换类别特征无压力——Qiita 很方便。 不要使用 get_dummies …","link":"/2021/08/12/pyFM-vs-fastFM/"},{"title":"开源软件商用","text":"开源协议是否可以商用（总结） Apache BSD GPL MIT Mozilla 能否商用 Apache Licence是对商业应用友好的许可。使用者也可以在需要的时候修改代码来满足需要并作为开源或商业产品发布/销售。 商业软件可以使用，也可以修改使用BSD协议的代码。 商业软件不能使用GPL协议的代码。 商业软件可以使用，也可以修改MIT协议的代码，甚至可以出售MIT协议的代码。 商业软件可以使用，也可以修改MPL协议的代码，但修改后的代码版权归软件的发起者。 其他参考","link":"/2021/09/03/%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E5%95%86%E7%94%A8/"},{"title":"打不开 leetcode-cn.com","text":"Solution1ping leetcode-cn.com 无法ping通打开常用域名解析地址文件 /ect/hosts删除 leetcode-cn.com 这一行","link":"/2021/10/05/%E6%89%93%E4%B8%8D%E5%BC%80leetcode-cn-com/"},{"title":"枚举所有子集","text":"Problem 枚举全集的所有子集枚举数组 $a={1,2,3,6}$的所有子集 解答 solution构建 $[0, 2^n]$ 到 $a$ 的所有子集的双射从 0000 枚举到 1111 代码 code123int n = a.size()for (int i = 0; i &lt; (1 &lt;&lt; n); ++i) {} Problem 枚举非全集的所有子集三个字符串 A=’abd’, B=’be’, C=’df’枚举每个字符串的所有子集 解答 solution构建二进制表示 A=001011, B=010010, C=101000对于A的所有子集，subset从A开始枚举，然后迭代subset -= 1，然后限制在A空间上 subset &amp;= A 即 subset = (subset - 1) &amp; A变换前后subset在A空间上至多相差1，因为它们在全空间上相差1，也就是说变换前后subset在A空间上要么相等要么相邻由于每个subset在A空间之外的分量都是0然后嵌入到全空间上，subset-1必然导致subset在A空间上发生改变，所以变换前后subset在A空间上是相邻的，这样就完成了对非全空间A的所有子集的顺序遍历 代码 code123for (int subset = A; subset; ) { subset = (subset - 1) &amp; A;}","link":"/2021/02/26/%E6%9E%9A%E4%B8%BE%E6%89%80%E6%9C%89%E5%AD%90%E9%9B%86/"},{"title":"物料智能编码","text":"背景 Why物料编码是 ERP 信息化的一个基本问题。物料具有多种属性，不同的物料其名称可能是相同的，不能仅根据物料名称来区分不同物料，需要给每种物料一个唯一的编码。对物料进行编码的过程中，由于存在地区时间的差异等因素，会出现一种物料多个编码的情况，这就容易造成物资积压、调度性差、资源浪费等问题。因此我们需要一个便于录入读取并且易于扩展的物料编码解决方案。 问题描述 What对于多种（可能高达数十万种）物料，并且物料的种类可能随着时间不断增加，如何给每种物料一个编码，要求： 每种物料的编码唯一，且一旦确定就不再更改 给定一个编码，相关工作人员不需查询就容易知道是何种物料 给定一个物料，可以知道其编码是否已经存在 给定一个物料，若其编码已经存在，相关工作人员不需查询就容易知道其编码 案例 Example由于原始数据难以脱敏，现以三国人物作为物料 数据 data 姓名 表字 势力 武力 统帅 智力 内政 外交 魅力 忠诚 武器 坐骑 技能 曹操 孟德 魏 70 90 75 80 70 90 60 青釭剑 绝影 奸雄 诸葛亮 孔明 蜀 65 92 96 99 98 95 95 朱雀羽扇 木牛流马 八阵 关羽 云长 蜀 98 95 85 60 50 95 98 青龙偃月刀 赤兔 武圣 刘备 玄德 蜀 75 80 75 75 70 98 80 雌雄双股剑 的卢 仁德 张飞 翼德 蜀 97 80 80 50 60 75 98 丈八蛇矛 无 咆哮 吕布 奉先 群 100 75 50 50 60 70 30 方天画戟 赤兔 无双 董卓 仲颖 群 80 80 65 60 70 60 40 无 赤兔 暴虐 司马懿 仲达 魏 80 90 90 90 80 80 65 无 无 天命 孙权 仲谋 吴 70 85 75 80 70 85 65 吴六剑 无 制衡 周瑜 公瑾 吴 85 95 85 75 75 80 90 无 无 英姿 袁绍 本初 群 70 75 70 70 60 85 80 无 无 名门 张角 无 群 70 80 80 70 55 90 50 无 无 黄天 司马昭 子尚 晋 80 90 85 80 80 75 50 无 无 昭心 贾诩 文和 群 65 65 97 85 85 75 70 无 无 毒士 贾诩 文和 魏 65 65 97 85 85 75 90 无 无 毒士 荀彧 文若 魏 65 65 96 96 80 90 95 无 无 节命 荀攸 公达 魏 65 65 99 80 75 80 90 无 无 奇策 郭嘉 奉孝 魏 60 65 98 90 90 90 95 无 无 天妒 程昱 仲德 魏 85 85 92 80 70 70 90 无 无 设伏 姜维 伯约 蜀 88 90 92 88 80 85 95 无 无 志继 姜维 伯约 魏 88 90 92 80 75 80 75 无 无 挑衅 鲁肃 子敬 吴 70 80 90 80 95 75 90 无 无 缔盟 吕蒙 子明 吴 80 90 90 75 60 75 90 无 无 博学 陆逊 伯言 吴 70 90 92 75 70 80 90 无 无 连营 孙坚 文台 吴 95 90 80 70 70 90 80 古锭刀 无 英魂 许褚 仲康 魏 97 80 60 50 50 75 90 贯石斧 无 裸衣 典韦 无 魏 99 65 55 50 50 75 95 双戟 无 强袭 黄忠 汉升 蜀 95 80 75 60 60 70 85 麒麟弓 无 烈弓 马超 孟起 群 97 85 70 70 70 80 80 无 无 铁骑 马超 孟起 蜀 97 85 70 70 70 80 80 无 无 铁骑 赵云 子龙 蜀 96 70 75 70 70 90 95 银月霸王枪 无 龙胆 魏延 文长 蜀 93 80 82 70 60 65 85 无 无 狂骨 法正 孝直 蜀 74 79 97 74 69 88 95 无 无 恩怨 庞统 士元 蜀 65 65 96 90 90 75 90 无 无 涅槃 孙策 伯符 吴 94 90 65 70 70 90 80 无 无 激昂 太史慈 子义 吴 94 85 75 65 65 90 90 无 无 天义 甘宁 兴霸 吴 94 85 80 65 65 75 90 无 无 奇袭 张辽 文远 魏 93 85 80 65 70 85 85 无 无 突袭 徐晃 公明 魏 90 85 85 65 65 85 90 无 无 断粮 夏侯惇 元让 魏 94 88 70 65 65 88 95 无 无 刚烈 庞德 令明 魏 94 85 70 65 65 85 90 无 无 猛进 曹纯 子和 魏 70 75 75 70 65 80 95 无 无 缮甲 初步编码 tentative给每个人物唯一一个编码 外部环境规定每个属性的重要性，不同属性的重要性可以相同0 姓名 1 表字 势力 武器 坐骑 技能 2 武力 统帅 智力 内政 外交 魅力 忠诚 对于非数值型属性，重要性相同的属性按照信息熵由小到大排列0 姓名 1 势力 2 坐骑 3 武器 4 表字 5 技能 对于数值型属性，除非外部环境规定，一般不纳入编码规定加入 6 武力 7 智力 非数值型属性之间以拼音首字母(为了区分度可能增加至多个)大小写分割，数值型属性都用两位数字表示 编码 姓名 势力 坐骑 武器 表字 技能 武力 智力 CCweJYqgjMDjx7075 曹操 魏 绝影 青釭剑 孟德 奸雄 70 75 ZGLsMNLMzqysKMbz6596 诸葛亮 蜀 木牛流马 朱雀羽扇 孔明 八阵 65 96 GYsCTqlyydYCws9885 关羽 蜀 赤兔 青龙偃月刀 云长 武圣 98 85 优化后的编码 optimize 某些属性与主要属性的交叉熵比较大，去掉这些冗余的属性 信息熵较小且重要性较大的属性放在最前面便于分类 编码 姓名 势力 武力 智力 Ecc7075 曹操 魏 70 75 Szgl6596 诸葛亮 蜀 65 96 Sgy9885 关羽 蜀 98 85 Slb7575 刘备 蜀 75 75 Szf9780 张飞 蜀 97 80 Qlb0050 吕布 群 100 50 Qdz8065 董卓 群 80 65 Esmy8090 司马懿 魏 80 90 Usq7075 孙权 吴 70 75 Uzy8585 周瑜 吴 85 85 Qys7070 袁绍 群 70 70 Qzj7080 张角 群 70 80 Jsmz8085 司马昭 晋 80 85 Qjx6597 贾诩 群 65 97 Ejx6597 贾诩 魏 65 97 Exy6596 荀彧 魏 65 96 Exy6599 荀攸 魏 65 99 Egj6098 郭嘉 魏 60 98 Ecy8592 程昱 魏 85 92 Sjw8892 姜维 蜀 88 92 Ejw8892 姜维 魏 88 92 Uls7090 鲁肃 吴 70 90 Ulm8090 吕蒙 吴 80 90 Ulx7092 陆逊 吴 70 92 Usj9580 孙坚 吴 95 80 Exc9760 许褚 魏 97 60 Edw9955 典韦 魏 99 55 Shz9575 黄忠 蜀 95 75 Qmc9770 马超 群 97 70 Smc9770 马超 蜀 97 70 Szy9675 赵云 蜀 96 75 Swy9382 魏延 蜀 93 82 Sfz7497 法正 蜀 74 97 Spt6596 庞统 蜀 65 96 Usc9465 孙策 吴 94 65 Utsc9475 太史慈 吴 94 75 Ugn9480 甘宁 吴 94 80 Ezl9380 张辽 魏 93 80 Exh9085 徐晃 魏 90 85 Exhd9470 夏侯惇 魏 94 70 Epd9470 庞德 魏 94 70 Ecc7075zh 曹纯 魏 70 75 编码的可扩展性 scalability 每当产生冲突时，已经编码的物料其编码保持不变 对新添加的物料编码增加维度，优先选择信息熵较大的非数值型属性，综合考虑重要性、复杂度 姓名 表字 势力 武力 统帅 智力 内政 外交 魅力 忠诚 武器 坐骑 技能 曹操 孟德 魏 70 90 75 80 70 90 60 青釭剑 绝影 奸雄 曹纯 子和 魏 70 75 75 70 65 80 95 无 无 缮甲 编码 姓名 势力 武力 智力 表字 Ecc7075 曹操 魏 70 75 Ecc7075zh 曹纯 魏 70 75 子和 解决方案 How","link":"/2021/02/02/%E7%89%A9%E6%96%99%E6%99%BA%E8%83%BD%E7%BC%96%E7%A0%81/"},{"title":"Immunity to All Poisons, the 7th Level of Nine-Yang-Divine-Skill, for Network-Max-Flow","text":"网络最大流之九阳神功第七层「诸毒不侵」 Preface 前言The mechanic who wishes to do his work well,must first sharpen his tools. Having Solved the basic theoretical problems,immunity to all poisons,the 7th level of Nine-Yang-Divine-Skill,goes back to algorithmic problems again. 工欲善其事必先利其器， 解决了基本理论问题， 九阳神功第七层「诸毒不侵」再次回到算法问题。 Shortest Augmenting Path Algorithm 最短提升路算法Pseudo Code 伪代码123456789101112131415161718192021222324252627282930313233343536ALGORITHM ShortestAugmentingPath;BEGIN F := 0; init distance function D; init predecessor function Pred; v := s; WHILE D(s) &lt; n DO BEGIN IF v has an admissible arc THEN BEGIN Advance(v); if v == t then Augment() and v := s; END ELSE Retreat(v); ENDENDFUNCTION Advance(v);BEGIN get an admissible arc (v,w); Pred(w) := v; v := w;ENDFUNCTION Retreat(v);BEGIN D(v) := min{D(u)+1 : (u,v) in A, r(u,v)&gt;0}; IF v != s THEN v := Pred(v);ENDFUNCTION Augment;BEGIN P := the admissible augmenting path from s to t; delta := min{r(u,v) : (u,v) in A(P)}; augment delta units of flow F along path P;END Concept 概念$G=(V,A,~\\mathcal{C})$ is the network,with source $s\\in V$ and sink $t\\in V$. $\\forall\\text{ }u,v\\in V$.$P_{u,v}$ is a path from $u$ to $v$.$Q_{u,v}$ is a shortest path from $u$ to $v$. $A$ is symmetric:$(u,v)\\in A\\Longrightarrow(v,u)\\in A$. $f$ is a flow of $G$.$r=\\mathcal{C}-f$ is the residual of $G$ w.r.t. $f$.The residual network $G[r]=(V,A_r,r)$ satisfying $A_r=\\lbrace a\\in A:r(a)&gt;0\\rbrace$. DistanceThe distance from $v$ to $t$, denoted as $\\mathfrak{D}(v)$,is the length of $Q_{v,t}$. Quasi-DistanceA function $D:V\\longrightarrow\\mathbb{N}$ is called a quasi-distance,if $D(t)=0$ and $D(u)\\leq D(v)+1,\\text{ }\\forall\\text{ }(u,v)\\in A$. AdmissibleAn arc $(u,v)\\in A$ is called admissible w.r.t. $D$ if $D(u)=D(v)+1$.$P_{u,v}$ is called admissible if every arc of $P_{u,v}$ is admissible. ExactA quasi-distance $D$ is called exact if $D=\\mathfrak{D}$. Lemma 引理$\\underline{\\textbf{Lemma0}}$For any arc $(u,v)$,it holds $\\mathfrak{D}(u)=\\mathfrak{D}(v)-1\\text{ or }\\mathfrak{D}(v)\\text{ or }\\mathfrak{D}(v)+1$.So $\\mathfrak{D}$ is a quasi-distance. $\\textbf{proof:}$The extended path $(u,v)Q_{v,t}$ is a path from $u$ to $t$,thus leading to $\\mathfrak{D}(u)\\leq\\vert(u,v)Q_{v,t}\\vert=1+\\mathfrak{D}(v)$.Since $(u,v)\\in A\\Longrightarrow(v,u)\\in A$,the extended path $(v,u)Q_{u,t}$ is a path from $v$ to $t$,thus leading to $\\mathfrak{D}(v)\\leq\\vert(v,u)Q_{u,t}\\vert=1+\\mathfrak{D}(u)$.$\\square$ $\\underline{\\textbf{Lemma1}}$For any vertex $v\\in V$,there exists an admissible path $P_{v,t}$ w.r.t. $\\mathfrak{D}$,which is exactly $Q_{v,t}$. $\\textbf{proof:}$Since $G$ is connected and $A$ is symmetric,by BFS from $t$ backward to $v$,we get an admissible $v,t$ path $P_{v,t}$,which is of course the shortest path.$\\square$ $\\underline{\\textbf{Lemma2}}$For any quasi-distance $D$,it holds that $D\\leq\\mathfrak{D}$. $\\textbf{proof:}$For any vertex $v\\in V$,let the shortest path $Q_{v,t}=v_0v_1\\cdots v_l$,with $v_0=v$ and $v_l=t$.By definition of quasi-distance,$D(v_{l-1})\\leq D(v_l)+1=1$,$D(v_{l-2})\\leq D(v_{l-1})+1$,$\\vdots$$D(v_0)\\leq D(v_1)+1$.The summation gives $D(v)\\leq l=\\mathfrak{D}(v)$.$\\square$ $\\underline{\\textbf{Lemma3}}$In $G[r]$, if $D(s)\\geq\\vert V\\vert$,then $G[r]$ contains no path from $s$ to $t$. $\\textbf{proof:}$Suppose to the contrary $G[r]$ contains a path $Q_{s,t}$.By Lemma2, $D(s)\\leq\\mathfrak{D}(s)=\\vert Q_{s,t}\\vert\\leq\\vert V\\vert-1$,violating $D(s)\\geq\\vert V\\vert$.$\\square$ $\\underline{\\textbf{Lemma4}}$If $P_{s,t}$ is admissible w.r.t. $D$, then it’s a shortest path. $\\textbf{proof:}$Since $P_{s,t}$ is admissible,then $\\mathfrak{D}(s)\\leq\\vert P_{s,t}\\vert=D(s)$.By Lemma2, $D(s)\\leq\\mathfrak{D}(s)$.Therefore $D(s)=\\mathfrak{D}(s)$,meaning that $P_{s,t}$ is a shortest $s,t$ path.$\\square$ $\\underline{\\textbf{Lemma5}}$When the ShortestAugmentingPath algorithm terminates,the residual network contains no augmenting paths. $\\textbf{proof:}$when the algorithm terminates,it holds $D(s)\\geq\\vert V\\vert$.The result follows by Lemma3.$\\square$ $\\underline{\\textbf{Theorem6}}$When the ShortestAugmentingPath algorithm terminates,it outputs a max-flow of the network. $\\textbf{proof:}$By Lemma5, and Theorem0 ofGecko Roaming the Wall, the 6th Level of Nine-Yang-Divine-Skill, for Network-Max-Flow, 网络最大流之九阳神功第六层「壁虎游墙」.$\\square$ $\\underline{\\textbf{Theorem7}}$Suppose the algorithm terminates.Let $f_1,f_2,\\cdots,f_t$ be the flows the algorithm generates,$G[r_1],G[r_2],\\cdots,G[r_t]$ be the correspondent residual networks,and $D_1,D_2,\\cdots,D_t$ be the correspondent quasi-distance functions.Then $D_1\\leq D_2\\leq\\cdots\\leq D_t$.Furthurmore, for any $D_{i}\\leq D_{i+1}$,if no Retreat is operated,then $D_{i}=D_{i+1}$,otherwise there exists $v\\in V$,such that $D_{i}(v)&lt;D_{i+1}(v)$. Summary 小结This post introduces ShortestAugmentingPath algorithm. Reference 参考 Purple Qi of the Rich Mist, the 1st Level of Nine-Yang-Divine-Skill, for Network-Max-Flow, 网络最大流之九阳神功第一层「氤氲紫气」 Tendon Changing and Marrow Cleansing, the 2nd Level of Nine-Yang-Divine-Skill, for Network-Max-Flow, 网络最大流之九阳神功第二层「易筋洗髓」 Fiery Qi of the Ultimate Yang, the 3rd Level of Nine-Yang-Divine-Skill, for Network-Max-Flow, 网络最大流之九阳神功第三层「至阳热气」 Bone Shrinking Technique, the 4th Level of Nine-Yang-Divine-Skill, for Network-Max-Flow, 网络最大流之九阳神功第四层「缩骨大法」 Turtle Breathing Technique, the 5th Level of Nine-Yang-Divine-Skill, for Network-Max-Flow, 网络最大流之九阳神功第五层「龟息大法」 Gecko Roaming the Wall, the 6th Level of Nine-Yang-Divine-Skill, for Network-Max-Flow, 网络最大流之九阳神功第六层「壁虎游墙」 Immunity to All Poisons, the 7th Level of Nine-Yang-Divine-Skill, for Network-Max-Flow, 网络最大流之九阳神功第七层「诸毒不侵」 Indestructible Vajra Body, the 8th Level of Nine-Yang-Divine-Skill, for Network-Max-Flow, 网络最大流之九阳神功第八层「金刚不坏」 Rebound Attack, the 9th Level of Nine-Yang-Divine-Skill, for Network-Max-Flow, 网络最大流之九阳神功第九层「反弹攻击」 Stronger with Each Use, the 10th Level of Nine-Yang-Divine-Skill, for Network-Max-Flow, 网络最大流之九阳神功第十层「愈使愈强」","link":"/2024/03/06/%E7%BD%91%E7%BB%9C%E6%9C%80%E5%A4%A7%E6%B5%81%E4%B9%8B%E4%B9%9D%E9%98%B3%E7%A5%9E%E5%8A%9F%E7%AC%AC%E4%B8%83%E5%B1%82%E3%80%8C%E8%AF%B8%E6%AF%92%E4%B8%8D%E4%BE%B5%E3%80%8D/"},{"title":"Gecko Roaming the Wall, the 6th Level of Nine-Yang-Divine-Skill, for Network-Max-Flow","text":"网络最大流之九阳神功第六层「壁虎游墙」 Preface 前言It’s a ridge viewing from a horizontal perspective, while a peak from otherwise, with distinct distances and heights. To comprehend the nature of Network-Max-Flow, it’s required to observe it from various perspectives. Therefore, gecko roaming the wall, the 6th level of Nine-Yang-Divine-Skill, will continue to discuss theoretical problems. 横看成岭侧成峰，远近高低各不同。 欲识庐山真面目，就需要从各个角度去观察网络最大流。 所以九阳神功第六层「壁虎游墙」继续讨论理论问题。 Convergence Condition 算法收敛条件Augmenting-Path 提升路$G=(V,A,~\\mathcal{C})$ is a network,where $\\mathcal{C}:A\\longrightarrow\\mathbb{R}$ unless otherwise regulated.$P$ is an $s,t$ path of $G$.$f:A\\longrightarrow\\mathbb{R}$ is a flow of $G$.$r=\\mathcal{C}-f$ is the residual of $G$ with respect to $f$.Then $P$ is called an augmenting-path of $G$,if $r(a)&gt;0$ for any arc $a\\in A(P)$. Theorem0 定理0Alias of Convergence Condition Theorem. For any algorithm based on augmenting-paths, it’s always provided that: the network contains no augmenting-paths when the algorithm terminates. We’ll prove Theorem7 of the 5th level of Nine-Yang-Divine-Skill in the following pipeline. $\\underline{\\textbf{Theorem0}}$$f$ is a max-flow of $G$ iff $G$ contains no augmenting-paths. $\\textbf{proof:}$$”\\Longrightarrow”$ Obviously. If not, $f$ will be augmented.$”\\Longleftarrow”$ By Lemma2 there exists a cut $(S,\\bar S)$ s.t. $r(S,\\bar S)=0$. By Lemma3 of the 5th Level of Nine-Yang-Divine-Skill, $f$ is a max-flow.$\\square$ Lemma1 引理1Let $\\mathcal{P}(G)$ be the set of all $s,t$ paths of $G$, i.e. $\\mathcal{P}(G)=\\lbrace P:~P\\text{ is an }s,t\\text{ path of }G\\rbrace$. $\\underline{\\textbf{Lemma1}}$$G$ contains no augmenting-paths iff for any $P\\in\\mathcal{P}(G)$ there exists $a\\in A(P)$ s.t. $r(a)=0$. $\\textbf{proof:}$$”\\Longrightarrow”$ If not, there exists $P\\in\\mathcal{P}(G)$ s.t. for all $a\\in A(P):~r(a)\\neq0$. By $f$’s property (i) Bound, we have $r(a)&gt;0$. This means $P$ is an augmenting-path, violating that $G$ contains no augmenting-paths.$”\\Longleftarrow”$ Similarly using proof by contradiction.$\\square$ Lemma2 引理2Let $Q$ be a path starting with $s$ but not containing $t$. $Q$ is called an s-partial-augmenting-path(SPAP) of $G$, if $r(a)&gt;0$ for any arc $a\\in A(Q)$. Let $\\mathcal{Q}(G)=\\lbrace Q:~Q\\text{ is an SPAP of }G\\rbrace$. Let $V(\\mathcal{Q})=\\bigcup\\limits_{Q\\in\\mathcal{Q}(G)}V(Q)$. $\\underline{\\textbf{Lemma2}}$$G$ contains no augmenting-paths iff there exists a cut $(S,\\bar S)$ s.t. $r(S,\\bar S)=0$. $\\textbf{proof:}$$”\\Longleftarrow”$ $r(S,\\bar S)=0$ is equivalent to $r(a)=0,\\text{ }\\forall\\text{ }a\\in(S,\\bar S)$.By Lemma6, any $s,t$ path $P$ meets $(S,\\bar S)$ at $a\\in A(P)\\cap(S,\\bar S)$ with $r(a)=0$,indicating that $P$ isn’t an augmenting-path by Lemma1.$”\\Longrightarrow”$ Let $S=V(\\mathcal{Q})$ and we’ve done.It suffices to show $r(a)=0,\\text{ }\\forall\\text{ }a\\in(S,\\bar S)$.Suppose to the contrary that $\\exists\\text{ }a=(x,y)\\in(S,\\bar S)\\text{ s.t. }r(a)\\neq0$.By the definition of $V(\\mathcal{Q})$, there exists $Q\\in\\mathcal{Q}(G)$s.t. $x$ is a vertex, particularly the last vertex of $Q$.Since $r(a)&gt;0$, then the extended path $Qy\\in\\mathcal{Q}(G)$, violating that $y\\in\\bar S$.$\\square$ Corollary3 推论3If the loop of the algorithm is executed in finite steps,we call the algorithm terminates. $\\underline{\\textbf{Corollary3}}$If the algorithm terminates, then it outputs a max-flow of the network. $\\textbf{proof:}$The condition the algorithm terminates implies the network contains no augmenting-paths.The result follows by Theorem0.$\\square$ Is there any case in which the algorithm doesn’t terminate? Theorem4 定理4Next we’ll prove Lemma6 of the 5th Level of Nine-Yang-Divine-Skill in the following pipeline. $\\underline{\\textbf{Theorem4}}$If $\\mathcal{C}:A\\longrightarrow\\mathbb{Q}$ and $f:A\\longrightarrow\\mathbb{Q}$, then the algorithm terminates. $\\textbf{proof:}$For any $a_i\\in A$, let $\\mathcal{C}(a_i)=\\frac{x_i}{y_i}$ and $f(a_i)=\\frac{z_i}{w_i}$,where $x_i,y_i,z_i,w_i\\in\\mathbb{N}$ and $(x_i,y_i)=1,~(z_i,w_i)=1$.Let $M=\\prod\\limits_{i:a_i\\in A}y_iw_i$. Let $\\mathcal{C}’=M\\cdot\\mathcal{C}$ and $f’=M\\cdot f$.It’s easy to see $\\mathcal{C}’,f’$ are natural numbers.Applying Theorem5 to $\\mathcal{C}’,f’$ we’ve done.$\\square$ Theorem5 定理5$\\underline{\\textbf{Theorem5}}$If $\\mathcal{C}:A\\longrightarrow\\mathbb{N}$ and $f:A\\longrightarrow\\mathbb{N}$, then the algorithm terminates. $\\textbf{proof:}$Suppose to the contrary that the algorithm doesn’t terminate.Let $\\lbrace f_i\\rbrace_{i=0}^\\infty$ be the progression of flows generated by the algorithm.On one hand, since $\\mathcal{C},f$ is constrained from $\\mathbb{R}$ to $\\mathbb{N}$,then $\\vert f_i\\vert+1\\leq\\vert f_{i+1}\\vert,\\text{ }\\forall\\text{ }i\\in\\mathbb{N}$,which leads to $\\lim\\limits_{i\\to\\infty}\\vert f_i\\vert=\\infty$,meaning that the progression is unbounded.On the other hand, by Lemma1 and Lemma2 of the 5th Level of Nine-Yang-Divine-Skill, $\\vert f_i\\vert\\leq\\mathcal{C}(t_*),\\text{ }\\forall\\text{ }i\\in\\mathbb{N}$,meaning that the progression is upper-bounded by the capacity of the minimal cut, which is a contradiction.$\\square$ Lemma6 引理6This lemma asserts that an $s,t$ path ought to meet any cut of the network. $\\underline{\\textbf{Lemma6}}$Let $(S,\\bar S)$ be any cut, and $P$ be any $s,t$ path, of $G$. Then $A(P)\\cap(S,\\bar S)\\neq\\varnothing$. $\\textbf{proof:}$Let $P=v_0v_1\\cdots v_l$ with $v_0=s$ and $v_l=t$.Noting that $s\\in S$ and $t\\in\\bar S$,there exists a minimal index $i\\in\\lbrace1,2,\\cdots,l\\rbrace$ satisfying $v_i\\in\\bar S$,hence $(v_{i-1},v_i)\\in(S,\\bar S)$.$\\square$ Path Flow Decomposition 路径流量分解We’nna prove the theorem of the 4th Level of Nine-Yang-Divine-Skill in the following pipeline. Path Flow 路径流量$P$ is an $s,t$ path of $G$.$f$ is a flow of $G$.Then $f$ is called a path-flow of $G$,if $f(a)=C,\\text{ }\\forall\\text{ }a\\in A(P)$ for some constant $C\\in\\mathbb{R}$,and $f(a)=0,\\text{ }\\forall\\text{ }a\\in A\\setminus A(P)$. Let $f_P$ denote a flow satisfyingif $a\\in A(P)$, then $f_P(a)=1$;otherwise $f_P(a)=0$. Cycle Flow 环流$C$ is a cycle of $G$.$f$ is a flow of $G$.Then $f$ is called a cycle-flow of $G$,if $f(a)=T,\\text{ }\\forall\\text{ }a\\in A(C)$ for some constant $T\\in\\mathbb{R}$,and $f(a)=0,\\text{ }\\forall\\text{ }a\\in A\\setminus A(C)$. Theorem7 定理7Alias of Path Flow Decomposition Theorem. For capacity $\\mathcal{C}:A\\longrightarrow\\mathbb{R}$ and flow $f:A\\longrightarrow\\mathbb{R}$,we define an assignment operation from $f$ to $\\mathcal{C}$:$\\mathcal{C}\\leftarrow f$ as $\\forall\\text{ }(u,v)\\in A$,let $\\mathcal{C}(u,v)=\\mathcal{C}(v,u)=\\max\\lbrace f(u,v),f(v,u)\\rbrace$. We define a partial-order on flows:for $f,g\\in\\mathcal{F}(G)$, we say $f&lt;g$,if $f(u,v)\\leq g(u,v),\\text{ }\\forall\\text{ }(u,v)\\in A$,and $\\exists\\text{ }(u,v)\\in A\\text{ s.t. }f(u,v)&lt;g(u,v)$. We define an equivalent-relationship on flows:for $f,g\\in\\mathcal{F}(G)$, we say $f\\equiv g$,if $f,g$ differ by several cycle-flows. $\\underline{\\textbf{Theorem7}}$For any flow $f$ of $G$, there exists a progression $\\lbrace f_i\\rbrace_{i=1}^\\infty$ of path-flows of $G$s.t. $f=\\sum\\limits_{i=1}^\\infty f_i$. $\\textbf{proof:}$Let network $G’=(V,A,\\mathcal{C}’)$ with $\\mathcal{C}’\\longleftarrow f$,and obviously $f$ is a max-flow of $G’$.Let $f_0$ be the 0-flow of $G’$.Let $F_i=\\sum\\limits_{j=0}^if_j,\\text{ }\\forall\\text{ }i\\in\\mathbb{N}$.If there exists an augmenting-path $P_i$ of $G’$ with respect to $F_i$,which can be determined in polynomial time by some search method,let $f_{i+1}=\\delta\\cdot f_{P_i}$ with $\\delta=\\min\\limits_{a\\in A(P_i)}r(a)$;Otherwise let $f_{i+1}=f_{i+2}=\\cdots=0$,in which case obviously $f=F_i$ holds by Theorem0.It suffices to show $\\lim\\limits_{i\\to\\infty}F_i=f$,in the case that for every $F_i$ there exists $P_i$.Noting that $F_i&lt;F_{i+1}&lt;f,\\text{ }\\forall\\text{ }i\\in\\mathbb{N}$,then for every $(u,v)\\in A$ the progression $\\lbrace F_i(u,v)\\rbrace_{i=0}^\\infty$ converges.So let $\\lim\\limits_{i\\to\\infty}F_i=f’$ where $f’\\leq f$.Suppose to the contrary that $\\exists\\text{ }(u,v)\\in A$ satisfying $\\lim\\limits_{i\\to\\infty}F_i(u,v)=f’(u,v)&lt;f(u,v)$.If there exists no augmenting-paths containing $(u,v)$ with respect to $f’$,then $(u,v)$ is contained by several cycle-flows of $f-f’$,thus by Lemma8 $f’$ can be expressed as $\\sum\\limits_{i=1}^\\infty g_i$;Otherwise $\\exists P$ containing $(u,v)$ w.r.t. $f’$,let $\\delta=\\min\\limits_{a\\in A(P)}(f-f’)(u,v)$ and $g=f’+\\delta*f_P$,violating that $f’$ is the summation of all the $f_P$ s.$\\square$ Lemma8 引理8$\\underline{\\textbf{Lemma8}}$For any $f,g\\in\\mathcal{F}(G)$ satisfying $f\\equiv g$,if $f=\\sum\\limits_{i=1}^\\infty f_i$ for some progression $\\lbrace f_i\\rbrace_{i=1}^\\infty$ of flows of $G$,then $g=\\sum\\limits_{i=1}^\\infty g_i$ for some progression $\\lbrace g_i\\rbrace_{i=1}^\\infty$ of flows of $G$. $\\textbf{proof:}$Noting that a cycle-flow is a flow,and $f,g$ differ by several cycle-flows.$\\square$ Summary 小结This post demonstrates Convergence Condition Theorem of algorithms based on augmenting-paths technique. Also it demonstrates Path Flow Decomposition Theorem. Reference 参考 Purple Qi of the Rich Mist, the 1st Level of Nine-Yang-Divine-Skill, for Network-Max-Flow, 网络最大流之九阳神功第一层「氤氲紫气」 Tendon Changing and Marrow Cleansing, the 2nd Level of Nine-Yang-Divine-Skill, for Network-Max-Flow, 网络最大流之九阳神功第二层「易筋洗髓」 Fiery Qi of the Ultimate Yang, the 3rd Level of Nine-Yang-Divine-Skill, for Network-Max-Flow, 网络最大流之九阳神功第三层「至阳热气」 Bone Shrinking Technique, the 4th Level of Nine-Yang-Divine-Skill, for Network-Max-Flow, 网络最大流之九阳神功第四层「缩骨大法」 Turtle Breathing Technique, the 5th Level of Nine-Yang-Divine-Skill, for Network-Max-Flow, 网络最大流之九阳神功第五层「龟息大法」 Gecko Roaming the Wall, the 6th Level of Nine-Yang-Divine-Skill, for Network-Max-Flow, 网络最大流之九阳神功第六层「壁虎游墙」 Immunity to All Poisons, the 7th Level of Nine-Yang-Divine-Skill, for Network-Max-Flow, 网络最大流之九阳神功第七层「诸毒不侵」 Indestructible Vajra Body, the 8th Level of Nine-Yang-Divine-Skill, for Network-Max-Flow, 网络最大流之九阳神功第八层「金刚不坏」 Rebound Attack, the 9th Level of Nine-Yang-Divine-Skill, for Network-Max-Flow, 网络最大流之九阳神功第九层「反弹攻击」 Stronger with Each Use, the 10th Level of Nine-Yang-Divine-Skill, for Network-Max-Flow, 网络最大流之九阳神功第十层「愈使愈强」","link":"/2024/03/01/%E7%BD%91%E7%BB%9C%E6%9C%80%E5%A4%A7%E6%B5%81%E4%B9%8B%E4%B9%9D%E9%98%B3%E7%A5%9E%E5%8A%9F%E7%AC%AC%E5%85%AD%E5%B1%82%E3%80%8C%E5%A3%81%E8%99%8E%E6%B8%B8%E5%A2%99%E3%80%8D/"},{"title":"跑步","text":"0跟着180节奏音乐 1腹部绷紧找不到感觉=&gt; 肩背向下后方发力，腹部发力与之对抗 2前2公里中频小碎步热身 3腹部持续中度绷紧，其他部位放松，减少能耗 4最小化冗余动作和上下左右震动，减少能耗 5脚步落地一瞬，腹部增加发力形成支点，腿部借助势能微微发力迅速转化为前进动能 6呼气时腹部微微发力内卷，吸气时腹部自动还原至水平，肩背微微向后下方发力，两大臂自然向后夹住两肋，保持上身稳定 7落脚与大地融合，呼吸共长天一气 8跑量超标导致小腿内侧筋膜疼痛=&gt;弹力球按压恢复","link":"/2021/08/07/%E8%B7%91%E6%AD%A5/"}],"tags":[{"name":"Mac","slug":"Mac","link":"/tags/Mac/"},{"name":"homebrew","slug":"homebrew","link":"/tags/homebrew/"},{"name":"qita","slug":"qita","link":"/tags/qita/"},{"name":"CSDN","slug":"CSDN","link":"/tags/CSDN/"},{"name":"stackoverflow","slug":"stackoverflow","link":"/tags/stackoverflow/"},{"name":"coloring","slug":"coloring","link":"/tags/coloring/"},{"name":"vertex-coloring","slug":"vertex-coloring","link":"/tags/vertex-coloring/"},{"name":"chromatic-number","slug":"chromatic-number","link":"/tags/chromatic-number/"},{"name":"Brooks","slug":"Brooks","link":"/tags/Brooks/"},{"name":"CentOS","slug":"CentOS","link":"/tags/CentOS/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"MacOS","slug":"MacOS","link":"/tags/MacOS/"},{"name":"Docker","slug":"Docker","link":"/tags/Docker/"},{"name":"DeepFM","slug":"DeepFM","link":"/tags/DeepFM/"},{"name":"Github","slug":"Github","link":"/tags/Github/"},{"name":"Tensorflow","slug":"Tensorflow","link":"/tags/Tensorflow/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"kaggle","slug":"kaggle","link":"/tags/kaggle/"},{"name":"FM","slug":"FM","link":"/tags/FM/"},{"name":"ML","slug":"ML","link":"/tags/ML/"},{"name":"Kruskal","slug":"Kruskal","link":"/tags/Kruskal/"},{"name":"algorithm","slug":"algorithm","link":"/tags/algorithm/"},{"name":"LeetCode","slug":"LeetCode","link":"/tags/LeetCode/"},{"name":"Manim","slug":"Manim","link":"/tags/Manim/"},{"name":"hive","slug":"hive","link":"/tags/hive/"},{"name":"sql","slug":"sql","link":"/tags/sql/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"feature","slug":"feature","link":"/tags/feature/"},{"name":"Spark","slug":"Spark","link":"/tags/Spark/"},{"name":"SQL","slug":"SQL","link":"/tags/SQL/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"Icarus","slug":"Icarus","link":"/tags/Icarus/"},{"name":"WordPress","slug":"WordPress","link":"/tags/WordPress/"},{"name":"Google","slug":"Google","link":"/tags/Google/"},{"name":"召回","slug":"召回","link":"/tags/%E5%8F%AC%E5%9B%9E/"},{"name":"推荐系统","slug":"推荐系统","link":"/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"},{"name":"Tao","slug":"Tao","link":"/tags/Tao/"},{"name":"并查集","slug":"并查集","link":"/tags/%E5%B9%B6%E6%9F%A5%E9%9B%86/"},{"name":"洛谷","slug":"洛谷","link":"/tags/%E6%B4%9B%E8%B0%B7/"},{"name":"StackOverflow","slug":"StackOverflow","link":"/tags/StackOverflow/"},{"name":"macOS","slug":"macOS","link":"/tags/macOS/"},{"name":"file","slug":"file","link":"/tags/file/"},{"name":"model","slug":"model","link":"/tags/model/"},{"name":"encoding","slug":"encoding","link":"/tags/encoding/"},{"name":"tkinter","slug":"tkinter","link":"/tags/tkinter/"},{"name":"subset","slug":"subset","link":"/tags/subset/"},{"name":"space","slug":"space","link":"/tags/space/"},{"name":"ERP","slug":"ERP","link":"/tags/ERP/"},{"name":"三国","slug":"三国","link":"/tags/%E4%B8%89%E5%9B%BD/"},{"name":"九阳神功","slug":"九阳神功","link":"/tags/%E4%B9%9D%E9%98%B3%E7%A5%9E%E5%8A%9F/"},{"name":"Nine-Yang-Divine-Skill","slug":"Nine-Yang-Divine-Skill","link":"/tags/Nine-Yang-Divine-Skill/"},{"name":"网络最大流","slug":"网络最大流","link":"/tags/%E7%BD%91%E7%BB%9C%E6%9C%80%E5%A4%A7%E6%B5%81/"},{"name":"Network-Max-Flow","slug":"Network-Max-Flow","link":"/tags/Network-Max-Flow/"},{"name":"running","slug":"running","link":"/tags/running/"}],"categories":[{"name":"数学","slug":"数学","link":"/categories/%E6%95%B0%E5%AD%A6/"},{"name":"操作系统","slug":"操作系统","link":"/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"深度学习","slug":"深度学习","link":"/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"机器学习","slug":"机器学习","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"图论","slug":"数学/图论","link":"/categories/%E6%95%B0%E5%AD%A6/%E5%9B%BE%E8%AE%BA/"},{"name":"数据结构&amp;算法","slug":"数据结构-算法","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%AE%97%E6%B3%95/"},{"name":"debug","slug":"debug","link":"/categories/debug/"},{"name":"推荐系统","slug":"机器学习/推荐系统","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"},{"name":"博客","slug":"博客","link":"/categories/%E5%8D%9A%E5%AE%A2/"},{"name":"jupyter","slug":"jupyter","link":"/categories/jupyter/"},{"name":"工程项目","slug":"工程项目","link":"/categories/%E5%B7%A5%E7%A8%8B%E9%A1%B9%E7%9B%AE/"}]}